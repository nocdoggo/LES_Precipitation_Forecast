{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5d5d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /opt/tljh/user/lib/python3.8/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/tljh/user/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/tljh/user/lib/python3.8/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/jupyter-doggo/.local/lib/python3.8/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/tljh/user/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/jupyter-doggo/.local/lib/python3.8/site-packages (1.23.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /opt/tljh/user/lib/python3.8/site-packages (4.62.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad26cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a18a1",
   "metadata": {},
   "source": [
    "## `TO-DO`: Change `start_year`, `end_year`, and `weather_station` based on needs\n",
    "\n",
    "`filename` <String> : The meteorology data collected from each weather station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a4df98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI\n",
      "Weather station data exists for  MI-14850-TRAVERSE_CITY_CHERRY_CPTL_AP\n",
      "File exists, reading table!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167831/1416301442.py:22: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  temp_table = pd.read_csv('NSW_Weather/'+weather_station+'/'+filename, skiprows = 8, skipfooter = 15)\n"
     ]
    }
   ],
   "source": [
    "# Important, make sure to use the correct file\n",
    "weather_station = 'MI-14850-TRAVERSE_CITY_CHERRY_CPTL_AP'\n",
    "\n",
    "start_year = 2016\n",
    "end_year = 2017\n",
    "\n",
    "filename = weather_station[0:9]+str(start_year)+'Fall-'+str(end_year)+'Spring.csv'\n",
    "\n",
    "## Extract the state indicator\n",
    "STATE_ID = filename[:2]\n",
    "STATE_2_LTR = filename[:2]\n",
    "print(STATE_2_LTR)\n",
    "\n",
    "# Check if they exist\n",
    "if os.path.exists('NSW_Weather/'+weather_station+'/'):\n",
    "    print('Weather station data exists for ', weather_station)\n",
    "else:\n",
    "    print('Weather station data does not exist for ', weather_station)\n",
    "    \n",
    "if os.path.isfile('NSW_Weather/'+weather_station+'/'+filename):\n",
    "    print(\"File exists, reading table!\")\n",
    "    temp_table = pd.read_csv('NSW_Weather/'+weather_station+'/'+filename, skiprows = 8, skipfooter = 15)\n",
    "else:\n",
    "    print(\"File does not exist, please rewind!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c893ed5",
   "metadata": {},
   "source": [
    "**Retrieving the GOES satellite imagery data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c708358d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-D Lake Michigan data exists for  2016Fall  to  2017Spring\n",
      "2-D Lake Michigan data exists for  2016Fall  to  2017Spring\n"
     ]
    }
   ],
   "source": [
    "# folder_name = 'zone_0_2016Fall_2017Spring'\n",
    "# Construct folder_name for 1-D data\n",
    "# print(filename)\n",
    "folder_name = 'zone_0_'+filename[9:13]+'Fall_'+filename[18:22]+'Spring'\n",
    "# print(folder_name)\n",
    "\n",
    "# Acquire the folder location for 2-D lake data based on folder_name\n",
    "folder_name_2D = folder_name[0:7]+'T_'+folder_name[7:]\n",
    "# print(folder_name_2D)\n",
    "\n",
    "# Add the parent folder name\n",
    "parent_path = 'GOES_Hourly_Statistics/'\n",
    "\n",
    "# Check if they exist\n",
    "if os.path.exists(parent_path + folder_name):\n",
    "    print('1-D Lake Michigan data exists for ', folder_name[7:15], ' to ', folder_name[16:])\n",
    "else:\n",
    "    print('1-D Lake Michigan data does not exist for ', folder_name[7:15], ' to ', folder_name[16:])\n",
    "    \n",
    "if os.path.exists(parent_path + folder_name_2D):\n",
    "    print('2-D Lake Michigan data exists for ', folder_name_2D[9:17], ' to ', folder_name_2D[18:])\n",
    "else:\n",
    "    print('2-D Lake Michigan data does not exist for ', folder_name[9:17], ' to ', folder_name_2D[18:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3259c",
   "metadata": {},
   "source": [
    "**Optional:**\n",
    "You might have noticed that there is an empty column at the end of the table, since the footer of the weather station data contains extra words at the end. Therefore, it would be the best to drop it, but it is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45517c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Column at the end is dropped.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    temp_table = temp_table.drop('Unnamed: 18', axis = 1)\n",
    "    print('Empty Column at the end is dropped.')\n",
    "except:\n",
    "    print('Nothing to be dropped here.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fcc989e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Temp (F)</th>\n",
       "      <th>RH (%)</th>\n",
       "      <th>Dewpt (F)</th>\n",
       "      <th>Wind Spd (mph)</th>\n",
       "      <th>Wind Direction (deg)</th>\n",
       "      <th>Peak Wind Gust(mph)</th>\n",
       "      <th>Low Cloud Ht (ft)</th>\n",
       "      <th>Med Cloud Ht (ft)</th>\n",
       "      <th>High Cloud Ht (ft)</th>\n",
       "      <th>Visibility (mi)</th>\n",
       "      <th>Atm Press (hPa)</th>\n",
       "      <th>Sea Lev Press (hPa)</th>\n",
       "      <th>Altimeter (hPa)</th>\n",
       "      <th>Precip (in)</th>\n",
       "      <th>Wind Chill (F)</th>\n",
       "      <th>Heat Index (F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>00:53</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>m</td>\n",
       "      <td>2500</td>\n",
       "      <td>3100</td>\n",
       "      <td>5500</td>\n",
       "      <td>10</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.90</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>01:53</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>350</td>\n",
       "      <td>m</td>\n",
       "      <td>2100</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>10</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.60</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>02:53</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>350</td>\n",
       "      <td>m</td>\n",
       "      <td>2400</td>\n",
       "      <td>2900</td>\n",
       "      <td>7000</td>\n",
       "      <td>10</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.60</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>03:50</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>340</td>\n",
       "      <td>m</td>\n",
       "      <td>2000</td>\n",
       "      <td>2700</td>\n",
       "      <td>7500</td>\n",
       "      <td>10</td>\n",
       "      <td>997.00</td>\n",
       "      <td>M</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>04:53</td>\n",
       "      <td>62</td>\n",
       "      <td>89</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>m</td>\n",
       "      <td>1700</td>\n",
       "      <td>2500</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.80</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Time Temp (F) RH (%)  Dewpt (F) Wind Spd (mph)  \\\n",
       "0  2016-09-01  00:53       66     69         56              9   \n",
       "1  2016-09-01  01:53       66     72         57              7   \n",
       "2  2016-09-01  02:53       66     69         56              6   \n",
       "3  2016-09-01  03:50       64     77         57              5   \n",
       "4  2016-09-01  04:53       62     89         59              7   \n",
       "\n",
       "  Wind Direction (deg) Peak Wind Gust(mph) Low Cloud Ht (ft)  \\\n",
       "0                   40                   m              2500   \n",
       "1                  350                   m              2100   \n",
       "2                  350                   m              2400   \n",
       "3                  340                   m              2000   \n",
       "4                   70                   m              1700   \n",
       "\n",
       "  Med Cloud Ht (ft) High Cloud Ht (ft) Visibility (mi) Atm Press (hPa)  \\\n",
       "0              3100               5500              10          997.00   \n",
       "1                 m                  m              10          997.00   \n",
       "2              2900               7000              10          997.00   \n",
       "3              2700               7500              10          997.00   \n",
       "4              2500                  m               3          997.00   \n",
       "\n",
       "  Sea Lev Press (hPa) Altimeter (hPa) Precip (in) Wind Chill (F)  \\\n",
       "0             1019.90         1020.00        0.00             NC   \n",
       "1             1019.60         1020.00        0.00             NC   \n",
       "2             1019.60         1020.00        0.00             NC   \n",
       "3                   M         1020.00        0.00             NC   \n",
       "4             1019.80         1020.00        0.20             NC   \n",
       "\n",
       "  Heat Index (F)  \n",
       "0             NC  \n",
       "1             NC  \n",
       "2             NC  \n",
       "3             NC  \n",
       "4             NC  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_table.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b007025",
   "metadata": {},
   "source": [
    "### Generate all possible time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62ea0e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, date\n",
    "\n",
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days) + 1):\n",
    "        yield date1 + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58138358",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dt = date(start_year, 10, 1)\n",
    "end_dt = date(end_year, 3, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "644a0676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20161001\n",
      "20161002\n",
      "20161003\n",
      "20161004\n",
      "20161005\n",
      "20161006\n",
      "20161007\n",
      "20161008\n",
      "20161009\n",
      "20161010\n",
      "20161011\n",
      "20161012\n",
      "20161013\n",
      "20161014\n",
      "20161015\n",
      "20161016\n",
      "20161017\n",
      "20161018\n",
      "20161019\n",
      "20161020\n",
      "20161021\n",
      "20161022\n",
      "20161023\n",
      "20161024\n",
      "20161025\n",
      "20161026\n",
      "20161027\n",
      "20161028\n",
      "20161029\n",
      "20161030\n",
      "20161031\n",
      "20161101\n",
      "20161102\n",
      "20161103\n",
      "20161104\n",
      "20161105\n",
      "20161106\n",
      "20161107\n",
      "20161108\n",
      "20161109\n",
      "20161110\n",
      "20161111\n",
      "20161112\n",
      "20161113\n",
      "20161114\n",
      "20161115\n",
      "20161116\n",
      "20161117\n",
      "20161118\n",
      "20161119\n",
      "20161120\n",
      "20161121\n",
      "20161122\n",
      "20161123\n",
      "20161124\n",
      "20161125\n",
      "20161126\n",
      "20161127\n",
      "20161128\n",
      "20161129\n",
      "20161130\n",
      "20161201\n",
      "20161202\n",
      "20161203\n",
      "20161204\n",
      "20161205\n",
      "20161206\n",
      "20161207\n",
      "20161208\n",
      "20161209\n",
      "20161210\n",
      "20161211\n",
      "20161212\n",
      "20161213\n",
      "20161214\n",
      "20161215\n",
      "20161216\n",
      "20161217\n",
      "20161218\n",
      "20161219\n",
      "20161220\n",
      "20161221\n",
      "20161222\n",
      "20161223\n",
      "20161224\n",
      "20161225\n",
      "20161226\n",
      "20161227\n",
      "20161228\n",
      "20161229\n",
      "20161230\n",
      "20161231\n",
      "20170101\n",
      "20170102\n",
      "20170103\n",
      "20170104\n",
      "20170105\n",
      "20170106\n",
      "20170107\n",
      "20170108\n",
      "20170109\n",
      "20170110\n",
      "20170111\n",
      "20170112\n",
      "20170113\n",
      "20170114\n",
      "20170115\n",
      "20170116\n",
      "20170117\n",
      "20170118\n",
      "20170119\n",
      "20170120\n",
      "20170121\n",
      "20170122\n",
      "20170123\n",
      "20170124\n",
      "20170125\n",
      "20170126\n",
      "20170127\n",
      "20170128\n",
      "20170129\n",
      "20170130\n",
      "20170131\n",
      "20170201\n",
      "20170202\n",
      "20170203\n",
      "20170204\n",
      "20170205\n",
      "20170206\n",
      "20170207\n",
      "20170208\n",
      "20170209\n",
      "20170210\n",
      "20170211\n",
      "20170212\n",
      "20170213\n",
      "20170214\n",
      "20170215\n",
      "20170216\n",
      "20170217\n",
      "20170218\n",
      "20170219\n",
      "20170220\n",
      "20170221\n",
      "20170222\n",
      "20170223\n",
      "20170224\n",
      "20170225\n",
      "20170226\n",
      "20170227\n",
      "20170228\n",
      "20170301\n",
      "20170302\n",
      "20170303\n",
      "20170304\n",
      "20170305\n",
      "20170306\n",
      "20170307\n",
      "20170308\n",
      "20170309\n",
      "20170310\n",
      "20170311\n",
      "20170312\n",
      "20170313\n",
      "20170314\n",
      "20170315\n",
      "20170316\n",
      "20170317\n",
      "20170318\n",
      "20170319\n",
      "20170320\n",
      "20170321\n",
      "20170322\n",
      "20170323\n",
      "20170324\n",
      "20170325\n",
      "20170326\n",
      "20170327\n",
      "20170328\n",
      "20170329\n",
      "20170330\n",
      "20170331\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "for dt in daterange(start_dt, end_dt):\n",
    "    print(dt.strftime(\"%Y%m%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf3544f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_date_theo = [dt.strftime(\"%Y%m%d\") for dt in daterange(start_dt, end_dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a00abfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20161001',\n",
       " '20161002',\n",
       " '20161003',\n",
       " '20161004',\n",
       " '20161005',\n",
       " '20161006',\n",
       " '20161007',\n",
       " '20161008',\n",
       " '20161009',\n",
       " '20161010',\n",
       " '20161011',\n",
       " '20161012',\n",
       " '20161013',\n",
       " '20161014',\n",
       " '20161015',\n",
       " '20161016',\n",
       " '20161017',\n",
       " '20161018',\n",
       " '20161019',\n",
       " '20161020',\n",
       " '20161021',\n",
       " '20161022',\n",
       " '20161023',\n",
       " '20161024',\n",
       " '20161025',\n",
       " '20161026',\n",
       " '20161027',\n",
       " '20161028',\n",
       " '20161029',\n",
       " '20161030',\n",
       " '20161031',\n",
       " '20161101',\n",
       " '20161102',\n",
       " '20161103',\n",
       " '20161104',\n",
       " '20161105',\n",
       " '20161106',\n",
       " '20161107',\n",
       " '20161108',\n",
       " '20161109',\n",
       " '20161110',\n",
       " '20161111',\n",
       " '20161112',\n",
       " '20161113',\n",
       " '20161114',\n",
       " '20161115',\n",
       " '20161116',\n",
       " '20161117',\n",
       " '20161118',\n",
       " '20161119',\n",
       " '20161120',\n",
       " '20161121',\n",
       " '20161122',\n",
       " '20161123',\n",
       " '20161124',\n",
       " '20161125',\n",
       " '20161126',\n",
       " '20161127',\n",
       " '20161128',\n",
       " '20161129',\n",
       " '20161130',\n",
       " '20161201',\n",
       " '20161202',\n",
       " '20161203',\n",
       " '20161204',\n",
       " '20161205',\n",
       " '20161206',\n",
       " '20161207',\n",
       " '20161208',\n",
       " '20161209',\n",
       " '20161210',\n",
       " '20161211',\n",
       " '20161212',\n",
       " '20161213',\n",
       " '20161214',\n",
       " '20161215',\n",
       " '20161216',\n",
       " '20161217',\n",
       " '20161218',\n",
       " '20161219',\n",
       " '20161220',\n",
       " '20161221',\n",
       " '20161222',\n",
       " '20161223',\n",
       " '20161224',\n",
       " '20161225',\n",
       " '20161226',\n",
       " '20161227',\n",
       " '20161228',\n",
       " '20161229',\n",
       " '20161230',\n",
       " '20161231',\n",
       " '20170101',\n",
       " '20170102',\n",
       " '20170103',\n",
       " '20170104',\n",
       " '20170105',\n",
       " '20170106',\n",
       " '20170107',\n",
       " '20170108',\n",
       " '20170109',\n",
       " '20170110',\n",
       " '20170111',\n",
       " '20170112',\n",
       " '20170113',\n",
       " '20170114',\n",
       " '20170115',\n",
       " '20170116',\n",
       " '20170117',\n",
       " '20170118',\n",
       " '20170119',\n",
       " '20170120',\n",
       " '20170121',\n",
       " '20170122',\n",
       " '20170123',\n",
       " '20170124',\n",
       " '20170125',\n",
       " '20170126',\n",
       " '20170127',\n",
       " '20170128',\n",
       " '20170129',\n",
       " '20170130',\n",
       " '20170131',\n",
       " '20170201',\n",
       " '20170202',\n",
       " '20170203',\n",
       " '20170204',\n",
       " '20170205',\n",
       " '20170206',\n",
       " '20170207',\n",
       " '20170208',\n",
       " '20170209',\n",
       " '20170210',\n",
       " '20170211',\n",
       " '20170212',\n",
       " '20170213',\n",
       " '20170214',\n",
       " '20170215',\n",
       " '20170216',\n",
       " '20170217',\n",
       " '20170218',\n",
       " '20170219',\n",
       " '20170220',\n",
       " '20170221',\n",
       " '20170222',\n",
       " '20170223',\n",
       " '20170224',\n",
       " '20170225',\n",
       " '20170226',\n",
       " '20170227',\n",
       " '20170228',\n",
       " '20170301',\n",
       " '20170302',\n",
       " '20170303',\n",
       " '20170304',\n",
       " '20170305',\n",
       " '20170306',\n",
       " '20170307',\n",
       " '20170308',\n",
       " '20170309',\n",
       " '20170310',\n",
       " '20170311',\n",
       " '20170312',\n",
       " '20170313',\n",
       " '20170314',\n",
       " '20170315',\n",
       " '20170316',\n",
       " '20170317',\n",
       " '20170318',\n",
       " '20170319',\n",
       " '20170320',\n",
       " '20170321',\n",
       " '20170322',\n",
       " '20170323',\n",
       " '20170324',\n",
       " '20170325',\n",
       " '20170326',\n",
       " '20170327',\n",
       " '20170328',\n",
       " '20170329',\n",
       " '20170330',\n",
       " '20170331']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One more inspection\n",
    "weather_date_theo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b2899",
   "metadata": {},
   "source": [
    "### Check if any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3676b962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are supposed to be 182 days in the given period.\n"
     ]
    }
   ],
   "source": [
    "range_day_count = len(weather_date_theo)\n",
    "print('There are supposed to be {0} days in the given period.'.format(range_day_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54570b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are supposed to be 4368 hours in total in the given period.\n"
     ]
    }
   ],
   "source": [
    "range_hour_count = range_day_count * 24\n",
    "print('There are supposed to be {0} hours in total in the given period.'.format(range_hour_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1808ce",
   "metadata": {},
   "source": [
    "#### Do notice that the weather station data, we would need to round the timestamp to the nearest hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83b896ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad it out to 24 hours\n",
    "import itertools\n",
    "\n",
    "csv_date_list = list(itertools.chain.from_iterable(itertools.repeat(x, 24) for x in weather_date_theo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ede6d2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4368"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csv_date_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a90619",
   "metadata": {},
   "source": [
    "### Create the list of hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b765b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_lib = ['00:00', '01:00', '02:00', '03:00', '04:00', '05:00', '06:00', '07:00', '08:00', '09:00', \n",
    "            '10:00', '11:00', '12:00', '13:00', '14:00', '15:00', '16:00', '17:00',\n",
    "            '18:00', '19:00', '20:00', '21:00', '22:00', '23:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e21766c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_time_list = hour_lib * len(weather_date_theo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20a996eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspection only\n",
    "# csv_time_list[:26]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c0c3f3",
   "metadata": {},
   "source": [
    "**We need to notice that there are 2 possible timezones in this case, one is `Central Standard Time`, another one is `Eastern Standard Time`. For states in Illinois and Wisconsin, there is no need to change the date and time after converting the timestamp to the nearest hour. However, due to the timezone difference in other states such as Michigan, you will need to dial back the time by one hour to convert it to Central Standard Time without Daylight Savings.**\n",
    "\n",
    "There is 1 hour difference. Therefore, we rely on one parameter `STATE`, which extracts the first 2 letters of the file name, to properly align the time stamps together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4113f4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather station is from MI\n"
     ]
    }
   ],
   "source": [
    "# Inspection\n",
    "print('The weather station is from', STATE_2_LTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61153362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tester = weather_date_theo[:5]\n",
    "# tester.pop(0)\n",
    "# tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f6574e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tester.append(str(int(tester[-1])+1))\n",
    "# tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60945efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def round_datetime_to_nearest_hour(obj_arr, STATE_ID):\n",
    "    arr_len = len(obj_arr)\n",
    "    Date_CST = []\n",
    "    Time_CST = []\n",
    "    for i in range(arr_len):\n",
    "        # iterate through\n",
    "        date_item = obj_arr['Date'][i]\n",
    "        time_item = obj_arr['Time'][i]\n",
    "        t = datetime.strptime(date_item + \" \" + time_item, \"%Y-%m-%d %H:%M\")\n",
    "        # Calculate the number of minutes past the last full hour\n",
    "        minutes_past_hour = t.minute + t.second / 60\n",
    "        # Round up to the next whole number of hours if the time is more than 30 minutes past the hour,\n",
    "        # or round down to the current hour if it's less than 30 minutes past\n",
    "        if minutes_past_hour >= 30:\n",
    "            num_hours = math.ceil(minutes_past_hour / 60)\n",
    "        else:\n",
    "            num_hours = 0\n",
    "        # Create a new datetime object representing the rounded time\n",
    "        if STATE_ID in ['IL', 'WI']:\n",
    "            # No need to dial back one hour\n",
    "            rounded_time_temp = t + timedelta(hours=num_hours)\n",
    "        else:\n",
    "            rounded_time_temp = t + timedelta(hours=num_hours-1)\n",
    "        rounded_time=datetime(year=rounded_time_temp.year,\n",
    "                         month=rounded_time_temp.month,\n",
    "                         day=rounded_time_temp.day,\n",
    "                         hour=rounded_time_temp.hour, minute=0, second=0)\n",
    "        result_stamp = rounded_time.strftime(\"%Y-%m-%d %H:%M\")\n",
    "        \n",
    "        new_date, new_time = result_stamp.split(' ')\n",
    "        Date_CST.append(new_date)\n",
    "        Time_CST.append(new_time)\n",
    "        \n",
    "    obj_arr['Date_CST'] = Date_CST\n",
    "    obj_arr['Time_CST'] = Time_CST\n",
    "    return obj_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c839f08",
   "metadata": {},
   "source": [
    "**We need to notice that there are 2 possible timezones in this case, one is `Central Standard Time`, another one is `Eastern Standard Time`**\n",
    "\n",
    "There is 1 hour difference. Therefore, we rely on one parameter `STATE`, which extracts the first 2 letters of the file name, to properly align the time stamps together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7388c31d",
   "metadata": {},
   "source": [
    "### Add the rounded time into the weather station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cbbbdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "weather_with_CST = round_datetime_to_nearest_hour(temp_table, STATE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a592507c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Temp (F)</th>\n",
       "      <th>RH (%)</th>\n",
       "      <th>Dewpt (F)</th>\n",
       "      <th>Wind Spd (mph)</th>\n",
       "      <th>Wind Direction (deg)</th>\n",
       "      <th>Peak Wind Gust(mph)</th>\n",
       "      <th>Low Cloud Ht (ft)</th>\n",
       "      <th>Med Cloud Ht (ft)</th>\n",
       "      <th>High Cloud Ht (ft)</th>\n",
       "      <th>Visibility (mi)</th>\n",
       "      <th>Atm Press (hPa)</th>\n",
       "      <th>Sea Lev Press (hPa)</th>\n",
       "      <th>Altimeter (hPa)</th>\n",
       "      <th>Precip (in)</th>\n",
       "      <th>Wind Chill (F)</th>\n",
       "      <th>Heat Index (F)</th>\n",
       "      <th>Date_CST</th>\n",
       "      <th>Time_CST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>00:53</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>m</td>\n",
       "      <td>2500</td>\n",
       "      <td>3100</td>\n",
       "      <td>5500</td>\n",
       "      <td>10</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.90</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>01:53</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>350</td>\n",
       "      <td>m</td>\n",
       "      <td>2100</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>10</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.60</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>02:53</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>350</td>\n",
       "      <td>m</td>\n",
       "      <td>2400</td>\n",
       "      <td>2900</td>\n",
       "      <td>7000</td>\n",
       "      <td>10</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.60</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>03:50</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>340</td>\n",
       "      <td>m</td>\n",
       "      <td>2000</td>\n",
       "      <td>2700</td>\n",
       "      <td>7500</td>\n",
       "      <td>10</td>\n",
       "      <td>997.00</td>\n",
       "      <td>M</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>04:53</td>\n",
       "      <td>62</td>\n",
       "      <td>89</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>m</td>\n",
       "      <td>1700</td>\n",
       "      <td>2500</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.80</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>05:53</td>\n",
       "      <td>63</td>\n",
       "      <td>83</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>2400</td>\n",
       "      <td>3000</td>\n",
       "      <td>5500</td>\n",
       "      <td>10</td>\n",
       "      <td>997.70</td>\n",
       "      <td>1020.50</td>\n",
       "      <td>1020.70</td>\n",
       "      <td>0.27</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>06:53</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>m</td>\n",
       "      <td>2700</td>\n",
       "      <td>3600</td>\n",
       "      <td>5500</td>\n",
       "      <td>10</td>\n",
       "      <td>998.30</td>\n",
       "      <td>1021.20</td>\n",
       "      <td>1021.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>07:53</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>m</td>\n",
       "      <td>2400</td>\n",
       "      <td>6000</td>\n",
       "      <td>m</td>\n",
       "      <td>10</td>\n",
       "      <td>998.70</td>\n",
       "      <td>1021.50</td>\n",
       "      <td>1021.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>08:53</td>\n",
       "      <td>65</td>\n",
       "      <td>75</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>m</td>\n",
       "      <td>2000</td>\n",
       "      <td>3200</td>\n",
       "      <td>4700</td>\n",
       "      <td>10</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1022.00</td>\n",
       "      <td>1022.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>09:51</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>350</td>\n",
       "      <td>m</td>\n",
       "      <td>2300</td>\n",
       "      <td>3900</td>\n",
       "      <td>4600</td>\n",
       "      <td>10</td>\n",
       "      <td>999.60</td>\n",
       "      <td>M</td>\n",
       "      <td>1022.70</td>\n",
       "      <td>m</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>09:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Time Temp (F) RH (%)  Dewpt (F) Wind Spd (mph)  \\\n",
       "0  2016-09-01  00:53       66     69         56              9   \n",
       "1  2016-09-01  01:53       66     72         57              7   \n",
       "2  2016-09-01  02:53       66     69         56              6   \n",
       "3  2016-09-01  03:50       64     77         57              5   \n",
       "4  2016-09-01  04:53       62     89         59              7   \n",
       "5  2016-09-01  05:53       63     83         58              0   \n",
       "6  2016-09-01  06:53       63     86         59              5   \n",
       "7  2016-09-01  07:53       64     77         57              6   \n",
       "8  2016-09-01  08:53       65     75         57              8   \n",
       "9  2016-09-01  09:51       66     72         57              7   \n",
       "\n",
       "  Wind Direction (deg) Peak Wind Gust(mph) Low Cloud Ht (ft)  \\\n",
       "0                   40                   m              2500   \n",
       "1                  350                   m              2100   \n",
       "2                  350                   m              2400   \n",
       "3                  340                   m              2000   \n",
       "4                   70                   m              1700   \n",
       "5                    0                   m              2400   \n",
       "6                   50                   m              2700   \n",
       "7                   60                   m              2400   \n",
       "8                   60                   m              2000   \n",
       "9                  350                   m              2300   \n",
       "\n",
       "  Med Cloud Ht (ft) High Cloud Ht (ft) Visibility (mi) Atm Press (hPa)  \\\n",
       "0              3100               5500              10          997.00   \n",
       "1                 m                  m              10          997.00   \n",
       "2              2900               7000              10          997.00   \n",
       "3              2700               7500              10          997.00   \n",
       "4              2500                  m               3          997.00   \n",
       "5              3000               5500              10          997.70   \n",
       "6              3600               5500              10          998.30   \n",
       "7              6000                  m              10          998.70   \n",
       "8              3200               4700              10          999.00   \n",
       "9              3900               4600              10          999.60   \n",
       "\n",
       "  Sea Lev Press (hPa) Altimeter (hPa) Precip (in) Wind Chill (F)  \\\n",
       "0             1019.90         1020.00        0.00             NC   \n",
       "1             1019.60         1020.00        0.00             NC   \n",
       "2             1019.60         1020.00        0.00             NC   \n",
       "3                   M         1020.00        0.00             NC   \n",
       "4             1019.80         1020.00        0.20             NC   \n",
       "5             1020.50         1020.70        0.27             NC   \n",
       "6             1021.20         1021.30        0.00             NC   \n",
       "7             1021.50         1021.70        0.00             NC   \n",
       "8             1022.00         1022.00        0.00             NC   \n",
       "9                   M         1022.70           m             NC   \n",
       "\n",
       "  Heat Index (F)    Date_CST Time_CST  \n",
       "0             NC  2016-09-01    00:00  \n",
       "1             NC  2016-09-01    01:00  \n",
       "2             NC  2016-09-01    02:00  \n",
       "3             NC  2016-09-01    03:00  \n",
       "4             NC  2016-09-01    04:00  \n",
       "5             NC  2016-09-01    05:00  \n",
       "6             NC  2016-09-01    06:00  \n",
       "7             NC  2016-09-01    07:00  \n",
       "8             NC  2016-09-01    08:00  \n",
       "9             NC  2016-09-01    09:00  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform inspection\n",
    "weather_with_CST.head(10)\n",
    "# Make sure you scroll to the right to check the newly added data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fee49ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_with_CST['Precip (in)'] = weather_with_CST['Precip (in)'].replace('m', 0).astype(float)\n",
    "weather_with_CST['Temp (F)'] = weather_with_CST['Temp (F)'].replace('M', 200).astype(int)\n",
    "\n",
    "is_snow_precip = ((weather_with_CST['Precip (in)'] > 0) & (weather_with_CST['Temp (F)']  <= 32)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf126522",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_with_CST['is_snow_precip'] = is_snow_precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caa18d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Temp (F)</th>\n",
       "      <th>RH (%)</th>\n",
       "      <th>Dewpt (F)</th>\n",
       "      <th>Wind Spd (mph)</th>\n",
       "      <th>Wind Direction (deg)</th>\n",
       "      <th>Peak Wind Gust(mph)</th>\n",
       "      <th>Low Cloud Ht (ft)</th>\n",
       "      <th>Med Cloud Ht (ft)</th>\n",
       "      <th>...</th>\n",
       "      <th>Visibility (mi)</th>\n",
       "      <th>Atm Press (hPa)</th>\n",
       "      <th>Sea Lev Press (hPa)</th>\n",
       "      <th>Altimeter (hPa)</th>\n",
       "      <th>Precip (in)</th>\n",
       "      <th>Wind Chill (F)</th>\n",
       "      <th>Heat Index (F)</th>\n",
       "      <th>Date_CST</th>\n",
       "      <th>Time_CST</th>\n",
       "      <th>is_snow_precip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>00:53</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>m</td>\n",
       "      <td>2500</td>\n",
       "      <td>3100</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.90</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>01:53</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>350</td>\n",
       "      <td>m</td>\n",
       "      <td>2100</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.60</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>01:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>02:53</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>350</td>\n",
       "      <td>m</td>\n",
       "      <td>2400</td>\n",
       "      <td>2900</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.60</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>02:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>03:50</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>340</td>\n",
       "      <td>m</td>\n",
       "      <td>2000</td>\n",
       "      <td>2700</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>997.00</td>\n",
       "      <td>M</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>03:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>04:53</td>\n",
       "      <td>62</td>\n",
       "      <td>89</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>m</td>\n",
       "      <td>1700</td>\n",
       "      <td>2500</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.80</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>04:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Time  Temp (F) RH (%)  Dewpt (F) Wind Spd (mph)  \\\n",
       "0  2016-09-01  00:53        66     69         56              9   \n",
       "1  2016-09-01  01:53        66     72         57              7   \n",
       "2  2016-09-01  02:53        66     69         56              6   \n",
       "3  2016-09-01  03:50        64     77         57              5   \n",
       "4  2016-09-01  04:53        62     89         59              7   \n",
       "\n",
       "  Wind Direction (deg) Peak Wind Gust(mph) Low Cloud Ht (ft)  \\\n",
       "0                   40                   m              2500   \n",
       "1                  350                   m              2100   \n",
       "2                  350                   m              2400   \n",
       "3                  340                   m              2000   \n",
       "4                   70                   m              1700   \n",
       "\n",
       "  Med Cloud Ht (ft)  ... Visibility (mi) Atm Press (hPa) Sea Lev Press (hPa)  \\\n",
       "0              3100  ...              10          997.00             1019.90   \n",
       "1                 m  ...              10          997.00             1019.60   \n",
       "2              2900  ...              10          997.00             1019.60   \n",
       "3              2700  ...              10          997.00                   M   \n",
       "4              2500  ...               3          997.00             1019.80   \n",
       "\n",
       "  Altimeter (hPa) Precip (in)  Wind Chill (F) Heat Index (F)    Date_CST  \\\n",
       "0         1020.00         0.0              NC             NC  2016-09-01   \n",
       "1         1020.00         0.0              NC             NC  2016-09-01   \n",
       "2         1020.00         0.0              NC             NC  2016-09-01   \n",
       "3         1020.00         0.0              NC             NC  2016-09-01   \n",
       "4         1020.00         0.2              NC             NC  2016-09-01   \n",
       "\n",
       "  Time_CST is_snow_precip  \n",
       "0    00:00          False  \n",
       "1    01:00          False  \n",
       "2    02:00          False  \n",
       "3    03:00          False  \n",
       "4    04:00          False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_with_CST.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf6d9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_snow_24_120(df):\n",
    "    does_snow_24_120 = []\n",
    "    for i in range(len(df)):\n",
    "        if i + 120 < len(df):\n",
    "            if any(df['is_snow_precip'].iloc[i+24:i+120]):\n",
    "                does_snow_24_120.append(True)\n",
    "            else:\n",
    "                does_snow_24_120.append(False)\n",
    "        else:\n",
    "            does_snow_24_120.append(False)\n",
    "    df['does_snow_24_120'] = does_snow_24_120\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9c0a61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Temp (F)</th>\n",
       "      <th>RH (%)</th>\n",
       "      <th>Dewpt (F)</th>\n",
       "      <th>Wind Spd (mph)</th>\n",
       "      <th>Wind Direction (deg)</th>\n",
       "      <th>Peak Wind Gust(mph)</th>\n",
       "      <th>Low Cloud Ht (ft)</th>\n",
       "      <th>Med Cloud Ht (ft)</th>\n",
       "      <th>...</th>\n",
       "      <th>Atm Press (hPa)</th>\n",
       "      <th>Sea Lev Press (hPa)</th>\n",
       "      <th>Altimeter (hPa)</th>\n",
       "      <th>Precip (in)</th>\n",
       "      <th>Wind Chill (F)</th>\n",
       "      <th>Heat Index (F)</th>\n",
       "      <th>Date_CST</th>\n",
       "      <th>Time_CST</th>\n",
       "      <th>is_snow_precip</th>\n",
       "      <th>does_snow_24_120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>00:53</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>m</td>\n",
       "      <td>2500</td>\n",
       "      <td>3100</td>\n",
       "      <td>...</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.90</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>01:53</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>350</td>\n",
       "      <td>m</td>\n",
       "      <td>2100</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.60</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>01:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>02:53</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>350</td>\n",
       "      <td>m</td>\n",
       "      <td>2400</td>\n",
       "      <td>2900</td>\n",
       "      <td>...</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.60</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>02:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>03:50</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>340</td>\n",
       "      <td>m</td>\n",
       "      <td>2000</td>\n",
       "      <td>2700</td>\n",
       "      <td>...</td>\n",
       "      <td>997.00</td>\n",
       "      <td>M</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>03:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>04:53</td>\n",
       "      <td>62</td>\n",
       "      <td>89</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>m</td>\n",
       "      <td>1700</td>\n",
       "      <td>2500</td>\n",
       "      <td>...</td>\n",
       "      <td>997.00</td>\n",
       "      <td>1019.80</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>04:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Time  Temp (F) RH (%)  Dewpt (F) Wind Spd (mph)  \\\n",
       "0  2016-09-01  00:53        66     69         56              9   \n",
       "1  2016-09-01  01:53        66     72         57              7   \n",
       "2  2016-09-01  02:53        66     69         56              6   \n",
       "3  2016-09-01  03:50        64     77         57              5   \n",
       "4  2016-09-01  04:53        62     89         59              7   \n",
       "\n",
       "  Wind Direction (deg) Peak Wind Gust(mph) Low Cloud Ht (ft)  \\\n",
       "0                   40                   m              2500   \n",
       "1                  350                   m              2100   \n",
       "2                  350                   m              2400   \n",
       "3                  340                   m              2000   \n",
       "4                   70                   m              1700   \n",
       "\n",
       "  Med Cloud Ht (ft)  ... Atm Press (hPa) Sea Lev Press (hPa) Altimeter (hPa)  \\\n",
       "0              3100  ...          997.00             1019.90         1020.00   \n",
       "1                 m  ...          997.00             1019.60         1020.00   \n",
       "2              2900  ...          997.00             1019.60         1020.00   \n",
       "3              2700  ...          997.00                   M         1020.00   \n",
       "4              2500  ...          997.00             1019.80         1020.00   \n",
       "\n",
       "  Precip (in) Wind Chill (F)  Heat Index (F)    Date_CST Time_CST  \\\n",
       "0         0.0             NC              NC  2016-09-01    00:00   \n",
       "1         0.0             NC              NC  2016-09-01    01:00   \n",
       "2         0.0             NC              NC  2016-09-01    02:00   \n",
       "3         0.0             NC              NC  2016-09-01    03:00   \n",
       "4         0.2             NC              NC  2016-09-01    04:00   \n",
       "\n",
       "  is_snow_precip does_snow_24_120  \n",
       "0          False            False  \n",
       "1          False            False  \n",
       "2          False            False  \n",
       "3          False            False  \n",
       "4          False            False  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_with_CST = check_snow_24_120(weather_with_CST)\n",
    "weather_with_CST.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fead6ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Temp (F)</th>\n",
       "      <th>RH (%)</th>\n",
       "      <th>Dewpt (F)</th>\n",
       "      <th>Wind Spd (mph)</th>\n",
       "      <th>Wind Direction (deg)</th>\n",
       "      <th>Peak Wind Gust(mph)</th>\n",
       "      <th>Low Cloud Ht (ft)</th>\n",
       "      <th>Med Cloud Ht (ft)</th>\n",
       "      <th>...</th>\n",
       "      <th>Atm Press (hPa)</th>\n",
       "      <th>Sea Lev Press (hPa)</th>\n",
       "      <th>Altimeter (hPa)</th>\n",
       "      <th>Precip (in)</th>\n",
       "      <th>Wind Chill (F)</th>\n",
       "      <th>Heat Index (F)</th>\n",
       "      <th>Date_CST</th>\n",
       "      <th>Time_CST</th>\n",
       "      <th>is_snow_precip</th>\n",
       "      <th>does_snow_24_120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>14:53</td>\n",
       "      <td>60</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>220</td>\n",
       "      <td>m</td>\n",
       "      <td>25000</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>986.40</td>\n",
       "      <td>1009.40</td>\n",
       "      <td>1009.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>14:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>15:53</td>\n",
       "      <td>60</td>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>m</td>\n",
       "      <td>25000</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>987.00</td>\n",
       "      <td>1009.80</td>\n",
       "      <td>1009.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>15:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>16:53</td>\n",
       "      <td>54</td>\n",
       "      <td>71</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>25000</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>987.30</td>\n",
       "      <td>1010.50</td>\n",
       "      <td>1010.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>16:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>17:53</td>\n",
       "      <td>51</td>\n",
       "      <td>82</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>m</td>\n",
       "      <td>25000</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>988.00</td>\n",
       "      <td>1011.20</td>\n",
       "      <td>1010.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>17:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>18:53</td>\n",
       "      <td>49</td>\n",
       "      <td>83</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>25000</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>988.70</td>\n",
       "      <td>1011.60</td>\n",
       "      <td>1011.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>18:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>02:53</td>\n",
       "      <td>20</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>310</td>\n",
       "      <td>m</td>\n",
       "      <td>4700</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.00</td>\n",
       "      <td>1031.40</td>\n",
       "      <td>1030.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NC</td>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>02:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>03:53</td>\n",
       "      <td>20</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>310</td>\n",
       "      <td>m</td>\n",
       "      <td>3500</td>\n",
       "      <td>4800</td>\n",
       "      <td>...</td>\n",
       "      <td>1006.60</td>\n",
       "      <td>1031.00</td>\n",
       "      <td>1029.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NC</td>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>03:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612</th>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>04:53</td>\n",
       "      <td>19</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>280</td>\n",
       "      <td>m</td>\n",
       "      <td>3500</td>\n",
       "      <td>4700</td>\n",
       "      <td>...</td>\n",
       "      <td>1006.60</td>\n",
       "      <td>1030.80</td>\n",
       "      <td>1029.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NC</td>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>04:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4613</th>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>05:53</td>\n",
       "      <td>18</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>280</td>\n",
       "      <td>m</td>\n",
       "      <td>2600</td>\n",
       "      <td>5000</td>\n",
       "      <td>...</td>\n",
       "      <td>1006.60</td>\n",
       "      <td>1031.10</td>\n",
       "      <td>1029.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NC</td>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>05:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4614</th>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>06:51</td>\n",
       "      <td>18</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>260</td>\n",
       "      <td>m</td>\n",
       "      <td>2600</td>\n",
       "      <td>3800</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.00</td>\n",
       "      <td>M</td>\n",
       "      <td>1030.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>NC</td>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>06:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1406 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   Time  Temp (F) RH (%)  Dewpt (F) Wind Spd (mph)  \\\n",
       "1790  2016-11-14  14:53        60     47         40              6   \n",
       "1791  2016-11-14  15:53        60     49         41              6   \n",
       "1792  2016-11-14  16:53        54     71         45              7   \n",
       "1793  2016-11-14  17:53        51     82         46              3   \n",
       "1794  2016-11-14  18:53        49     83         44              0   \n",
       "...          ...    ...       ...    ...        ...            ...   \n",
       "4610  2017-03-12  02:53        20     51          5             10   \n",
       "4611  2017-03-12  03:53        20     51          5             10   \n",
       "4612  2017-03-12  04:53        19     61          8              7   \n",
       "4613  2017-03-12  05:53        18     64          8              5   \n",
       "4614  2017-03-12  06:51        18     72         10              5   \n",
       "\n",
       "     Wind Direction (deg) Peak Wind Gust(mph) Low Cloud Ht (ft)  \\\n",
       "1790                  220                   m             25000   \n",
       "1791                    M                   m             25000   \n",
       "1792                   10                   m             25000   \n",
       "1793                   50                   m             25000   \n",
       "1794                    0                   m             25000   \n",
       "...                   ...                 ...               ...   \n",
       "4610                  310                   m              4700   \n",
       "4611                  310                   m              3500   \n",
       "4612                  280                   m              3500   \n",
       "4613                  280                   m              2600   \n",
       "4614                  260                   m              2600   \n",
       "\n",
       "     Med Cloud Ht (ft)  ... Atm Press (hPa) Sea Lev Press (hPa)  \\\n",
       "1790                 m  ...          986.40             1009.40   \n",
       "1791                 m  ...          987.00             1009.80   \n",
       "1792                 m  ...          987.30             1010.50   \n",
       "1793                 m  ...          988.00             1011.20   \n",
       "1794                 m  ...          988.70             1011.60   \n",
       "...                ...  ...             ...                 ...   \n",
       "4610                 m  ...         1007.00             1031.40   \n",
       "4611              4800  ...         1006.60             1031.00   \n",
       "4612              4700  ...         1006.60             1030.80   \n",
       "4613              5000  ...         1006.60             1031.10   \n",
       "4614              3800  ...         1007.00                   M   \n",
       "\n",
       "     Altimeter (hPa) Precip (in) Wind Chill (F)  Heat Index (F)    Date_CST  \\\n",
       "1790         1009.10         0.0             NC              NC  2016-11-14   \n",
       "1791         1009.80         0.0             NC              NC  2016-11-14   \n",
       "1792         1010.20         0.0             NC              NC  2016-11-14   \n",
       "1793         1010.80         0.0             NC              NC  2016-11-14   \n",
       "1794         1011.50         0.0             NC              NC  2016-11-14   \n",
       "...              ...         ...            ...             ...         ...   \n",
       "4610         1030.10         0.0              9              NC  2017-03-12   \n",
       "4611         1029.80         0.0              9              NC  2017-03-12   \n",
       "4612         1029.80         0.0             10              NC  2017-03-12   \n",
       "4613         1029.80         0.0             11              NC  2017-03-12   \n",
       "4614         1030.10         0.0             11              NC  2017-03-12   \n",
       "\n",
       "     Time_CST is_snow_precip does_snow_24_120  \n",
       "1790    14:00          False             True  \n",
       "1791    15:00          False             True  \n",
       "1792    16:00          False             True  \n",
       "1793    17:00          False             True  \n",
       "1794    18:00          False             True  \n",
       "...       ...            ...              ...  \n",
       "4610    02:00          False             True  \n",
       "4611    03:00          False             True  \n",
       "4612    04:00          False             True  \n",
       "4613    05:00          False             True  \n",
       "4614    06:00          False             True  \n",
       "\n",
       "[1406 rows x 22 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_with_CST[weather_with_CST['does_snow_24_120'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40ca7644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Temp (F)</th>\n",
       "      <th>RH (%)</th>\n",
       "      <th>Dewpt (F)</th>\n",
       "      <th>Wind Spd (mph)</th>\n",
       "      <th>Wind Direction (deg)</th>\n",
       "      <th>Peak Wind Gust(mph)</th>\n",
       "      <th>Low Cloud Ht (ft)</th>\n",
       "      <th>Med Cloud Ht (ft)</th>\n",
       "      <th>...</th>\n",
       "      <th>Atm Press (hPa)</th>\n",
       "      <th>Sea Lev Press (hPa)</th>\n",
       "      <th>Altimeter (hPa)</th>\n",
       "      <th>Precip (in)</th>\n",
       "      <th>Wind Chill (F)</th>\n",
       "      <th>Heat Index (F)</th>\n",
       "      <th>Date_CST</th>\n",
       "      <th>Time_CST</th>\n",
       "      <th>is_snow_precip</th>\n",
       "      <th>does_snow_24_120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>18:53</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>55</td>\n",
       "      <td>13</td>\n",
       "      <td>180</td>\n",
       "      <td>22</td>\n",
       "      <td>3000</td>\n",
       "      <td>5000</td>\n",
       "      <td>...</td>\n",
       "      <td>979.00</td>\n",
       "      <td>1001.50</td>\n",
       "      <td>1001.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>18:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>19:53</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>200</td>\n",
       "      <td>25</td>\n",
       "      <td>3100</td>\n",
       "      <td>9500</td>\n",
       "      <td>...</td>\n",
       "      <td>977.40</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>19:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>20:53</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>240</td>\n",
       "      <td>30</td>\n",
       "      <td>3000</td>\n",
       "      <td>4600</td>\n",
       "      <td>...</td>\n",
       "      <td>977.00</td>\n",
       "      <td>999.60</td>\n",
       "      <td>999.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>20:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>21:53</td>\n",
       "      <td>55</td>\n",
       "      <td>59</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>220</td>\n",
       "      <td>36</td>\n",
       "      <td>3400</td>\n",
       "      <td>4300</td>\n",
       "      <td>...</td>\n",
       "      <td>978.70</td>\n",
       "      <td>1001.40</td>\n",
       "      <td>1001.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>21:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>22:53</td>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>230</td>\n",
       "      <td>24</td>\n",
       "      <td>3400</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>979.40</td>\n",
       "      <td>1001.90</td>\n",
       "      <td>1002.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>22:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>23:53</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>240</td>\n",
       "      <td>32</td>\n",
       "      <td>3300</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>979.40</td>\n",
       "      <td>1002.20</td>\n",
       "      <td>1002.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>23:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>00:53</td>\n",
       "      <td>46</td>\n",
       "      <td>60</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>220</td>\n",
       "      <td>31</td>\n",
       "      <td>3300</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>980.00</td>\n",
       "      <td>1002.70</td>\n",
       "      <td>1002.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>01:53</td>\n",
       "      <td>45</td>\n",
       "      <td>57</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>230</td>\n",
       "      <td>32</td>\n",
       "      <td>3300</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>980.70</td>\n",
       "      <td>1003.30</td>\n",
       "      <td>1003.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>01:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>02:53</td>\n",
       "      <td>44</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>230</td>\n",
       "      <td>34</td>\n",
       "      <td>3300</td>\n",
       "      <td>4200</td>\n",
       "      <td>...</td>\n",
       "      <td>981.40</td>\n",
       "      <td>1003.90</td>\n",
       "      <td>1004.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>02:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>03:51</td>\n",
       "      <td>41</td>\n",
       "      <td>75</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>220</td>\n",
       "      <td>22</td>\n",
       "      <td>2100</td>\n",
       "      <td>3400</td>\n",
       "      <td>...</td>\n",
       "      <td>981.70</td>\n",
       "      <td>M</td>\n",
       "      <td>1004.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>03:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>04:53</td>\n",
       "      <td>40</td>\n",
       "      <td>76</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>240</td>\n",
       "      <td>16</td>\n",
       "      <td>2100</td>\n",
       "      <td>3000</td>\n",
       "      <td>...</td>\n",
       "      <td>981.40</td>\n",
       "      <td>1004.30</td>\n",
       "      <td>1004.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>04:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>05:51</td>\n",
       "      <td>37</td>\n",
       "      <td>86</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>210</td>\n",
       "      <td>m</td>\n",
       "      <td>1500</td>\n",
       "      <td>1900</td>\n",
       "      <td>...</td>\n",
       "      <td>981.40</td>\n",
       "      <td>M</td>\n",
       "      <td>1004.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>05:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>06:53</td>\n",
       "      <td>38</td>\n",
       "      <td>85</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>290</td>\n",
       "      <td>29</td>\n",
       "      <td>1400</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>982.40</td>\n",
       "      <td>1005.20</td>\n",
       "      <td>1005.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>27</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>06:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>07:53</td>\n",
       "      <td>35</td>\n",
       "      <td>88</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>1600</td>\n",
       "      <td>...</td>\n",
       "      <td>984.00</td>\n",
       "      <td>1006.90</td>\n",
       "      <td>1006.80</td>\n",
       "      <td>0.01</td>\n",
       "      <td>26</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>07:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>08:51</td>\n",
       "      <td>36</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>290</td>\n",
       "      <td>23</td>\n",
       "      <td>2600</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>985.00</td>\n",
       "      <td>M</td>\n",
       "      <td>1007.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>09:53</td>\n",
       "      <td>34</td>\n",
       "      <td>88</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>300</td>\n",
       "      <td>22</td>\n",
       "      <td>2200</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>986.00</td>\n",
       "      <td>1009.10</td>\n",
       "      <td>1008.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>09:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>10:51</td>\n",
       "      <td>34</td>\n",
       "      <td>86</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>300</td>\n",
       "      <td>m</td>\n",
       "      <td>1500</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>987.00</td>\n",
       "      <td>M</td>\n",
       "      <td>1009.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>11:51</td>\n",
       "      <td>32</td>\n",
       "      <td>86</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>290</td>\n",
       "      <td>25</td>\n",
       "      <td>1300</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>987.70</td>\n",
       "      <td>M</td>\n",
       "      <td>1010.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>11:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>12:53</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>300</td>\n",
       "      <td>28</td>\n",
       "      <td>1200</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>988.00</td>\n",
       "      <td>1011.20</td>\n",
       "      <td>1010.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>12:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>13:53</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>988.70</td>\n",
       "      <td>1012.10</td>\n",
       "      <td>1011.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>21</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>13:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>14:53</td>\n",
       "      <td>32</td>\n",
       "      <td>81</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>300</td>\n",
       "      <td>36</td>\n",
       "      <td>1500</td>\n",
       "      <td>3000</td>\n",
       "      <td>...</td>\n",
       "      <td>989.70</td>\n",
       "      <td>1013.20</td>\n",
       "      <td>1012.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>14:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>15:53</td>\n",
       "      <td>31</td>\n",
       "      <td>85</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>300</td>\n",
       "      <td>37</td>\n",
       "      <td>1500</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>990.70</td>\n",
       "      <td>1014.30</td>\n",
       "      <td>1013.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>15:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>16:53</td>\n",
       "      <td>33</td>\n",
       "      <td>71</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>310</td>\n",
       "      <td>41</td>\n",
       "      <td>2500</td>\n",
       "      <td>3500</td>\n",
       "      <td>...</td>\n",
       "      <td>991.70</td>\n",
       "      <td>1015.20</td>\n",
       "      <td>1014.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>16:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>17:53</td>\n",
       "      <td>33</td>\n",
       "      <td>71</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>320</td>\n",
       "      <td>44</td>\n",
       "      <td>2500</td>\n",
       "      <td>3000</td>\n",
       "      <td>...</td>\n",
       "      <td>992.70</td>\n",
       "      <td>1016.10</td>\n",
       "      <td>1015.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>17:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>18:53</td>\n",
       "      <td>32</td>\n",
       "      <td>78</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>310</td>\n",
       "      <td>48</td>\n",
       "      <td>2200</td>\n",
       "      <td>2800</td>\n",
       "      <td>...</td>\n",
       "      <td>993.30</td>\n",
       "      <td>1016.80</td>\n",
       "      <td>1016.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>18:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>19:51</td>\n",
       "      <td>32</td>\n",
       "      <td>74</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>320</td>\n",
       "      <td>41</td>\n",
       "      <td>2500</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>994.00</td>\n",
       "      <td>M</td>\n",
       "      <td>1016.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>19:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>20:53</td>\n",
       "      <td>32</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>310</td>\n",
       "      <td>39</td>\n",
       "      <td>2500</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>994.30</td>\n",
       "      <td>1018.10</td>\n",
       "      <td>1017.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>20:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>21:53</td>\n",
       "      <td>33</td>\n",
       "      <td>71</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>320</td>\n",
       "      <td>46</td>\n",
       "      <td>2700</td>\n",
       "      <td>3300</td>\n",
       "      <td>...</td>\n",
       "      <td>995.00</td>\n",
       "      <td>1018.50</td>\n",
       "      <td>1017.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>21:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>22:51</td>\n",
       "      <td>30</td>\n",
       "      <td>92</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>330</td>\n",
       "      <td>34</td>\n",
       "      <td>800</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>995.70</td>\n",
       "      <td>M</td>\n",
       "      <td>1018.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>22:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>23:53</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>320</td>\n",
       "      <td>37</td>\n",
       "      <td>1000</td>\n",
       "      <td>1500</td>\n",
       "      <td>...</td>\n",
       "      <td>996.30</td>\n",
       "      <td>1020.00</td>\n",
       "      <td>1019.30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>23:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   Time  Temp (F) RH (%)  Dewpt (F) Wind Spd (mph)  \\\n",
       "1890  2016-11-18  18:53        65     70         55             13   \n",
       "1891  2016-11-18  19:53        66     65         54             13   \n",
       "1892  2016-11-18  20:53        64     62         51             11   \n",
       "1893  2016-11-18  21:53        55     59         41             16   \n",
       "1894  2016-11-18  22:53        51     60         38             13   \n",
       "1895  2016-11-18  23:53        48     60         35             18   \n",
       "1896  2016-11-19  00:53        46     60         33             15   \n",
       "1897  2016-11-19  01:53        45     57         31             17   \n",
       "1898  2016-11-19  02:53        44     57         30             11   \n",
       "1899  2016-11-19  03:51        41     75         34              6   \n",
       "1900  2016-11-19  04:53        40     76         33             11   \n",
       "1901  2016-11-19  05:51        37     86         34              6   \n",
       "1902  2016-11-19  06:53        38     85         34             22   \n",
       "1903  2016-11-19  07:53        35     88         32             14   \n",
       "1904  2016-11-19  08:51        36     80         30             16   \n",
       "1905  2016-11-19  09:53        34     88         31             16   \n",
       "1906  2016-11-19  10:51        34     86         30             18   \n",
       "1907  2016-11-19  11:51        32     86         28             14   \n",
       "1908  2016-11-19  12:53        32     85         28             17   \n",
       "1909  2016-11-19  13:53        32     85         28             17   \n",
       "1910  2016-11-19  14:53        32     81         27             23   \n",
       "1911  2016-11-19  15:53        31     85         27             25   \n",
       "1912  2016-11-19  16:53        33     71         25             23   \n",
       "1913  2016-11-19  17:53        33     71         25             28   \n",
       "1914  2016-11-19  18:53        32     78         26             23   \n",
       "1915  2016-11-19  19:51        32     74         25             28   \n",
       "1916  2016-11-19  20:53        32     75         25             26   \n",
       "1917  2016-11-19  21:53        33     71         25             22   \n",
       "1918  2016-11-19  22:51        30     92         28             22   \n",
       "1919  2016-11-19  23:53        32     85         28             21   \n",
       "\n",
       "     Wind Direction (deg) Peak Wind Gust(mph) Low Cloud Ht (ft)  \\\n",
       "1890                  180                  22              3000   \n",
       "1891                  200                  25              3100   \n",
       "1892                  240                  30              3000   \n",
       "1893                  220                  36              3400   \n",
       "1894                  230                  24              3400   \n",
       "1895                  240                  32              3300   \n",
       "1896                  220                  31              3300   \n",
       "1897                  230                  32              3300   \n",
       "1898                  230                  34              3300   \n",
       "1899                  220                  22              2100   \n",
       "1900                  240                  16              2100   \n",
       "1901                  210                   m              1500   \n",
       "1902                  290                  29              1400   \n",
       "1903                  300                  30              1000   \n",
       "1904                  290                  23              2600   \n",
       "1905                  300                  22              2200   \n",
       "1906                  300                   m              1500   \n",
       "1907                  290                  25              1300   \n",
       "1908                  300                  28              1200   \n",
       "1909                  300                  30              1000   \n",
       "1910                  300                  36              1500   \n",
       "1911                  300                  37              1500   \n",
       "1912                  310                  41              2500   \n",
       "1913                  320                  44              2500   \n",
       "1914                  310                  48              2200   \n",
       "1915                  320                  41              2500   \n",
       "1916                  310                  39              2500   \n",
       "1917                  320                  46              2700   \n",
       "1918                  330                  34               800   \n",
       "1919                  320                  37              1000   \n",
       "\n",
       "     Med Cloud Ht (ft)  ... Atm Press (hPa) Sea Lev Press (hPa)  \\\n",
       "1890              5000  ...          979.00             1001.50   \n",
       "1891              9500  ...          977.40             1000.00   \n",
       "1892              4600  ...          977.00              999.60   \n",
       "1893              4300  ...          978.70             1001.40   \n",
       "1894                 m  ...          979.40             1001.90   \n",
       "1895                 m  ...          979.40             1002.20   \n",
       "1896                 m  ...          980.00             1002.70   \n",
       "1897                 m  ...          980.70             1003.30   \n",
       "1898              4200  ...          981.40             1003.90   \n",
       "1899              3400  ...          981.70                   M   \n",
       "1900              3000  ...          981.40             1004.30   \n",
       "1901              1900  ...          981.40                   M   \n",
       "1902                 m  ...          982.40             1005.20   \n",
       "1903              1600  ...          984.00             1006.90   \n",
       "1904                 m  ...          985.00                   M   \n",
       "1905                 m  ...          986.00             1009.10   \n",
       "1906                 m  ...          987.00                   M   \n",
       "1907                 m  ...          987.70                   M   \n",
       "1908                 m  ...          988.00             1011.20   \n",
       "1909                 m  ...          988.70             1012.10   \n",
       "1910              3000  ...          989.70             1013.20   \n",
       "1911                 m  ...          990.70             1014.30   \n",
       "1912              3500  ...          991.70             1015.20   \n",
       "1913              3000  ...          992.70             1016.10   \n",
       "1914              2800  ...          993.30             1016.80   \n",
       "1915                 m  ...          994.00                   M   \n",
       "1916                 m  ...          994.30             1018.10   \n",
       "1917              3300  ...          995.00             1018.50   \n",
       "1918                 m  ...          995.70                   M   \n",
       "1919              1500  ...          996.30             1020.00   \n",
       "\n",
       "     Altimeter (hPa) Precip (in) Wind Chill (F)  Heat Index (F)    Date_CST  \\\n",
       "1890         1001.70        0.00             NC              NC  2016-11-18   \n",
       "1891         1000.00        0.00             NC              NC  2016-11-18   \n",
       "1892          999.70        0.00             NC              NC  2016-11-18   \n",
       "1893         1001.40        0.00             NC              NC  2016-11-18   \n",
       "1894         1002.00        0.00             NC              NC  2016-11-18   \n",
       "1895         1002.00        0.00             41              NC  2016-11-18   \n",
       "1896         1002.70        0.00             40              NC  2016-11-19   \n",
       "1897         1003.40        0.00             38              NC  2016-11-19   \n",
       "1898         1004.10        0.00             38              NC  2016-11-19   \n",
       "1899         1004.40        0.00             37              NC  2016-11-19   \n",
       "1900         1004.10        0.00             33              NC  2016-11-19   \n",
       "1901         1004.10        0.00             32              NC  2016-11-19   \n",
       "1902         1005.10        0.01             27              NC  2016-11-19   \n",
       "1903         1006.80        0.01             26              NC  2016-11-19   \n",
       "1904         1007.80        0.00             26              NC  2016-11-19   \n",
       "1905         1008.80        0.00             24              NC  2016-11-19   \n",
       "1906         1009.80        0.00             23              NC  2016-11-19   \n",
       "1907         1010.50        0.00             22              NC  2016-11-19   \n",
       "1908         1010.80        0.00             21              NC  2016-11-19   \n",
       "1909         1011.50        0.01             21              NC  2016-11-19   \n",
       "1910         1012.50        0.00             19              NC  2016-11-19   \n",
       "1911         1013.50        0.00             17              NC  2016-11-19   \n",
       "1912         1014.60        0.00             21              NC  2016-11-19   \n",
       "1913         1015.60        0.00             19              NC  2016-11-19   \n",
       "1914         1016.30        0.00             19              NC  2016-11-19   \n",
       "1915         1016.90        0.00             18              NC  2016-11-19   \n",
       "1916         1017.30        0.00             18              NC  2016-11-19   \n",
       "1917         1017.90        0.00             21              NC  2016-11-19   \n",
       "1918         1018.60        0.00             17              NC  2016-11-19   \n",
       "1919         1019.30        0.01             20              NC  2016-11-19   \n",
       "\n",
       "     Time_CST is_snow_precip does_snow_24_120  \n",
       "1890    18:00          False             True  \n",
       "1891    19:00          False             True  \n",
       "1892    20:00          False             True  \n",
       "1893    21:00          False             True  \n",
       "1894    22:00          False             True  \n",
       "1895    23:00          False             True  \n",
       "1896    00:00          False             True  \n",
       "1897    01:00          False            False  \n",
       "1898    02:00          False            False  \n",
       "1899    03:00          False            False  \n",
       "1900    04:00          False            False  \n",
       "1901    05:00          False            False  \n",
       "1902    06:00          False            False  \n",
       "1903    07:00          False            False  \n",
       "1904    08:00          False            False  \n",
       "1905    09:00          False            False  \n",
       "1906    10:00          False            False  \n",
       "1907    11:00          False            False  \n",
       "1908    12:00          False            False  \n",
       "1909    13:00           True            False  \n",
       "1910    14:00          False            False  \n",
       "1911    15:00          False            False  \n",
       "1912    16:00          False            False  \n",
       "1913    17:00          False            False  \n",
       "1914    18:00          False            False  \n",
       "1915    19:00          False            False  \n",
       "1916    20:00          False            False  \n",
       "1917    21:00          False            False  \n",
       "1918    22:00          False            False  \n",
       "1919    23:00           True            False  \n",
       "\n",
       "[30 rows x 22 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_with_CST[1890:1920]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571d043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a03659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23efcae7",
   "metadata": {},
   "source": [
    "#### Convert to Pandas series for easy computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8df23f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       20161001\n",
       "1       20161001\n",
       "2       20161001\n",
       "3       20161001\n",
       "4       20161001\n",
       "          ...   \n",
       "4363    20170331\n",
       "4364    20170331\n",
       "4365    20170331\n",
       "4366    20170331\n",
       "4367    20170331\n",
       "Name: Date_CST, Length: 4368, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Date_CST = pd.Series(csv_date_list, name = 'Date_CST')\n",
    "Date_CST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5daa3946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       00:00\n",
       "1       01:00\n",
       "2       02:00\n",
       "3       03:00\n",
       "4       04:00\n",
       "        ...  \n",
       "4363    19:00\n",
       "4364    20:00\n",
       "4365    21:00\n",
       "4366    22:00\n",
       "4367    23:00\n",
       "Name: Time_CST, Length: 4368, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_CST = pd.Series(csv_time_list, name = 'Time_CST')\n",
    "Time_CST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db0bd29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Retrieve all the files under the GOES data folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a72994d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goes15.2016.10.01.0000.v01.nc-var1-t0.csv',\n",
       " 'goes15.2016.10.01.0030.v01.nc-var1-t0.csv',\n",
       " 'goes15.2016.10.01.0100.v01.nc-var1-t0.csv',\n",
       " 'goes15.2016.10.01.0115.v01.nc-var1-t0.csv',\n",
       " 'goes15.2016.10.01.0130.v01.nc-var1-t0.csv',\n",
       " 'goes15.2016.10.01.0145.v01.nc-var1-t0.csv']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of all files in the directory\n",
    "file_list_1D = os.listdir(parent_path + folder_name)\n",
    "\n",
    "# Sort the list of files (Necessary on Linux)\n",
    "file_list_1D.sort()\n",
    "\n",
    "# Print the list of files\n",
    "file_list_1D[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2694a376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_goes15.2016.10.01.0000.v01.nc-var1-t0.csv.csv',\n",
       " 'T_goes15.2016.10.01.0030.v01.nc-var1-t0.csv.csv',\n",
       " 'T_goes15.2016.10.01.0100.v01.nc-var1-t0.csv.csv',\n",
       " 'T_goes15.2016.10.01.0115.v01.nc-var1-t0.csv.csv',\n",
       " 'T_goes15.2016.10.01.0130.v01.nc-var1-t0.csv.csv',\n",
       " 'T_goes15.2016.10.01.0145.v01.nc-var1-t0.csv.csv']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of all files in the directory\n",
    "file_list_2D = os.listdir(parent_path + folder_name_2D)\n",
    "\n",
    "# Sort the list of files (Necessary on Linux)\n",
    "file_list_2D.sort()\n",
    "\n",
    "# Print the list of files\n",
    "file_list_2D[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d63a296c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016.10.01', '2016.10.01', '2016.10.01', '2016.10.01', '2016.10.01']\n",
      "Length of date list =  4368\n"
     ]
    }
   ],
   "source": [
    "intend_date_list = []\n",
    "\n",
    "for date in csv_date_list:\n",
    "    intend_date = date[:4] + '.' + date[4:6] + '.' + date[6:]\n",
    "    intend_date_list.append(intend_date)\n",
    "\n",
    "print(intend_date_list[:5])\n",
    "print('Length of date list = ', len(intend_date_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fba9c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000', '0100', '0200', '0300', '0400']\n",
      "Length of time list =  4368\n"
     ]
    }
   ],
   "source": [
    "intend_time_list = [t.replace(':', '') for t in csv_time_list]\n",
    "print(intend_time_list[:5])\n",
    "print('Length of time list = ', len(intend_time_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26725545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016.10.01.0000', '2016.10.01.0100', '2016.10.01.0200', '2016.10.01.0300', '2016.10.01.0400']\n"
     ]
    }
   ],
   "source": [
    "intend_timestamp_list = [f\"{date}.{time}\" for date, time in zip(intend_date_list, intend_time_list)]\n",
    "print(intend_timestamp_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03406b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016-10-01', '2016-10-01', '2016-10-01', '2016-10-01', '2016-10-01']\n",
      "Length of date list =  4368\n"
     ]
    }
   ],
   "source": [
    "Date_UTC = []\n",
    "\n",
    "for date in csv_date_list:\n",
    "    intend_date = date[:4] + '-' + date[4:6] + '-' + date[6:]\n",
    "    Date_UTC.append(intend_date)\n",
    "\n",
    "print(Date_UTC[:5])\n",
    "print('Length of date list = ', len(Date_UTC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aff978de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00:00', '01:00', '02:00', '03:00', '04:00']\n",
      "Length of time list =  4368\n"
     ]
    }
   ],
   "source": [
    "Time_UTC = csv_time_list.copy()\n",
    "\n",
    "print(Time_UTC[:5])\n",
    "print('Length of time list = ', len(Time_UTC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "643661db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016.10.01.0000', '2016.10.01.0030', '2016.10.01.0100', '2016.10.01.0115', '2016.10.01.0130']\n",
      "Len =  15622\n"
     ]
    }
   ],
   "source": [
    "file_1D_timestamp = []\n",
    "\n",
    "for filename in file_list_1D:\n",
    "    file_1D = filename[7:22]\n",
    "    file_1D_timestamp.append(file_1D)\n",
    "\n",
    "print(file_1D_timestamp[:5])\n",
    "print('Len = ', len(file_1D_timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eeb1c0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016-09-30', '2016-09-30', '2016-09-30', '2016-09-30', '2016-09-30']\n",
      "['18:00', '19:00', '20:00', '21:00', '22:00']\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "# Define UTC and CST time zones\n",
    "utc_tz = timezone('UTC')\n",
    "cst_tz = timezone('Etc/GMT+6')\n",
    "\n",
    "# Example lists of datetime strings\n",
    "date_utc_list = Date_UTC.copy()\n",
    "time_utc_list = Time_UTC.copy()\n",
    "\n",
    "# Convert datetime strings from UTC to CST\n",
    "date_cst_list = []\n",
    "time_cst_list = []\n",
    "for date_str, time_str in zip(date_utc_list, time_utc_list):\n",
    "    datetime_utc = datetime.strptime(date_str + ' ' + time_str, '%Y-%m-%d %H:%M')\n",
    "    datetime_utc = utc_tz.localize(datetime_utc)\n",
    "    datetime_cst = datetime_utc.astimezone(cst_tz)\n",
    "    date_cst_list.append(datetime_cst.strftime('%Y-%m-%d'))\n",
    "    time_cst_list.append(datetime_cst.strftime('%H:%M'))\n",
    "\n",
    "# Print the lists of datetime strings in CST\n",
    "print(date_cst_list[:5])  # Output: ['2023-01-01', '2023-01-02', '2023-01-03']\n",
    "print(time_cst_list[:5])  # Output: ['19:00', '06:00', '17:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0839fd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_UTC</th>\n",
       "      <th>Time_UTC</th>\n",
       "      <th>Date_CST</th>\n",
       "      <th>Time_CST</th>\n",
       "      <th>intend_timestamp_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>18:00</td>\n",
       "      <td>2016.10.01.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>01:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2016.10.01.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>02:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>20:00</td>\n",
       "      <td>2016.10.01.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>03:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>21:00</td>\n",
       "      <td>2016.10.01.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>04:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>22:00</td>\n",
       "      <td>2016.10.01.0400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date_UTC Time_UTC    Date_CST Time_CST intend_timestamp_list\n",
       "0  2016-10-01    00:00  2016-09-30    18:00       2016.10.01.0000\n",
       "1  2016-10-01    01:00  2016-09-30    19:00       2016.10.01.0100\n",
       "2  2016-10-01    02:00  2016-09-30    20:00       2016.10.01.0200\n",
       "3  2016-10-01    03:00  2016-09-30    21:00       2016.10.01.0300\n",
       "4  2016-10-01    04:00  2016-09-30    22:00       2016.10.01.0400"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = {'Date_UTC': Date_UTC,\n",
    "             'Time_UTC': Time_UTC,\n",
    "             'Date_CST': date_cst_list,\n",
    "             'Time_CST': time_cst_list,\n",
    "             'intend_timestamp_list': intend_timestamp_list}\n",
    "\n",
    "# create the DataFrame using the dictionary\n",
    "df_GOES_time_lib = pd.DataFrame(data_dict)\n",
    "df_GOES_time_lib.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389dcd7b",
   "metadata": {},
   "source": [
    "Form another dataframe with the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3cb0fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_timestamp</th>\n",
       "      <th>file_list_1D</th>\n",
       "      <th>file_list_2D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.10.01.0000</td>\n",
       "      <td>goes15.2016.10.01.0000.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0000.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016.10.01.0030</td>\n",
       "      <td>goes15.2016.10.01.0030.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0030.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.10.01.0100</td>\n",
       "      <td>goes15.2016.10.01.0100.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0100.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.10.01.0115</td>\n",
       "      <td>goes15.2016.10.01.0115.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0115.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.10.01.0130</td>\n",
       "      <td>goes15.2016.10.01.0130.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0130.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_timestamp                               file_list_1D  \\\n",
       "0  2016.10.01.0000  goes15.2016.10.01.0000.v01.nc-var1-t0.csv   \n",
       "1  2016.10.01.0030  goes15.2016.10.01.0030.v01.nc-var1-t0.csv   \n",
       "2  2016.10.01.0100  goes15.2016.10.01.0100.v01.nc-var1-t0.csv   \n",
       "3  2016.10.01.0115  goes15.2016.10.01.0115.v01.nc-var1-t0.csv   \n",
       "4  2016.10.01.0130  goes15.2016.10.01.0130.v01.nc-var1-t0.csv   \n",
       "\n",
       "                                      file_list_2D  \n",
       "0  T_goes15.2016.10.01.0000.v01.nc-var1-t0.csv.csv  \n",
       "1  T_goes15.2016.10.01.0030.v01.nc-var1-t0.csv.csv  \n",
       "2  T_goes15.2016.10.01.0100.v01.nc-var1-t0.csv.csv  \n",
       "3  T_goes15.2016.10.01.0115.v01.nc-var1-t0.csv.csv  \n",
       "4  T_goes15.2016.10.01.0130.v01.nc-var1-t0.csv.csv  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GOES_file_lib = pd.DataFrame({'file_timestamp': file_1D_timestamp, 'file_list_1D': file_list_1D, 'file_list_2D': file_list_2D})\n",
    "df_GOES_file_lib.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "425184e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_UTC</th>\n",
       "      <th>Time_UTC</th>\n",
       "      <th>Date_CST</th>\n",
       "      <th>Time_CST</th>\n",
       "      <th>intend_timestamp_list</th>\n",
       "      <th>file_timestamp</th>\n",
       "      <th>file_list_1D</th>\n",
       "      <th>file_list_2D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>18:00</td>\n",
       "      <td>2016.10.01.0000</td>\n",
       "      <td>2016.10.01.0000</td>\n",
       "      <td>goes15.2016.10.01.0000.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0000.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>01:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2016.10.01.0100</td>\n",
       "      <td>2016.10.01.0100</td>\n",
       "      <td>goes15.2016.10.01.0100.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0100.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>02:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>20:00</td>\n",
       "      <td>2016.10.01.0200</td>\n",
       "      <td>2016.10.01.0200</td>\n",
       "      <td>goes15.2016.10.01.0200.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0200.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>03:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>21:00</td>\n",
       "      <td>2016.10.01.0300</td>\n",
       "      <td>2016.10.01.0300</td>\n",
       "      <td>goes15.2016.10.01.0300.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0300.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>04:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>22:00</td>\n",
       "      <td>2016.10.01.0400</td>\n",
       "      <td>2016.10.01.0400</td>\n",
       "      <td>goes15.2016.10.01.0400.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0400.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>05:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>23:00</td>\n",
       "      <td>2016.10.01.0500</td>\n",
       "      <td>2016.10.01.0500</td>\n",
       "      <td>goes15.2016.10.01.0500.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0500.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>06:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2016.10.01.0600</td>\n",
       "      <td>2016.10.01.0600</td>\n",
       "      <td>goes15.2016.10.01.0600.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0600.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>07:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>01:00</td>\n",
       "      <td>2016.10.01.0700</td>\n",
       "      <td>2016.10.01.0700</td>\n",
       "      <td>goes15.2016.10.01.0700.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0700.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>08:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>02:00</td>\n",
       "      <td>2016.10.01.0800</td>\n",
       "      <td>2016.10.01.0800</td>\n",
       "      <td>goes15.2016.10.01.0800.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0800.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>09:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>03:00</td>\n",
       "      <td>2016.10.01.0900</td>\n",
       "      <td>2016.10.01.0900</td>\n",
       "      <td>goes15.2016.10.01.0900.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0900.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>10:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>04:00</td>\n",
       "      <td>2016.10.01.1000</td>\n",
       "      <td>2016.10.01.1000</td>\n",
       "      <td>goes15.2016.10.01.1000.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.1000.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>11:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>05:00</td>\n",
       "      <td>2016.10.01.1100</td>\n",
       "      <td>2016.10.01.1100</td>\n",
       "      <td>goes15.2016.10.01.1100.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.1100.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>12:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>06:00</td>\n",
       "      <td>2016.10.01.1200</td>\n",
       "      <td>2016.10.01.1200</td>\n",
       "      <td>goes15.2016.10.01.1200.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.1200.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>13:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>07:00</td>\n",
       "      <td>2016.10.01.1300</td>\n",
       "      <td>2016.10.01.1300</td>\n",
       "      <td>goes15.2016.10.01.1300.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.1300.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>14:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>08:00</td>\n",
       "      <td>2016.10.01.1400</td>\n",
       "      <td>2016.10.01.1400</td>\n",
       "      <td>goes15.2016.10.01.1400.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.1400.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>15:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>09:00</td>\n",
       "      <td>2016.10.01.1500</td>\n",
       "      <td>2016.10.01.1500</td>\n",
       "      <td>goes15.2016.10.01.1500.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.1500.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>16:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>10:00</td>\n",
       "      <td>2016.10.01.1600</td>\n",
       "      <td>2016.10.01.1600</td>\n",
       "      <td>goes15.2016.10.01.1600.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.1600.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>17:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>11:00</td>\n",
       "      <td>2016.10.01.1700</td>\n",
       "      <td>2016.10.01.1700</td>\n",
       "      <td>goes15.2016.10.01.1700.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.1700.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>18:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>12:00</td>\n",
       "      <td>2016.10.01.1800</td>\n",
       "      <td>2016.10.01.1800</td>\n",
       "      <td>goes15.2016.10.01.1800.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.1800.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>13:00</td>\n",
       "      <td>2016.10.01.1900</td>\n",
       "      <td>2016.10.01.1900</td>\n",
       "      <td>goes15.2016.10.01.1900.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.1900.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>20:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>14:00</td>\n",
       "      <td>2016.10.01.2000</td>\n",
       "      <td>2016.10.01.2000</td>\n",
       "      <td>goes15.2016.10.01.2000.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.2000.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>21:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>15:00</td>\n",
       "      <td>2016.10.01.2100</td>\n",
       "      <td>2016.10.01.2100</td>\n",
       "      <td>goes15.2016.10.01.2100.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.2100.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>22:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>16:00</td>\n",
       "      <td>2016.10.01.2200</td>\n",
       "      <td>2016.10.01.2200</td>\n",
       "      <td>goes15.2016.10.01.2200.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.2200.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>23:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>17:00</td>\n",
       "      <td>2016.10.01.2300</td>\n",
       "      <td>2016.10.01.2300</td>\n",
       "      <td>goes15.2016.10.01.2300.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.2300.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>18:00</td>\n",
       "      <td>2016.10.02.0000</td>\n",
       "      <td>2016.10.02.0000</td>\n",
       "      <td>goes15.2016.10.02.0000.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.0000.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>01:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2016.10.02.0100</td>\n",
       "      <td>2016.10.02.0100</td>\n",
       "      <td>goes15.2016.10.02.0100.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.0100.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>02:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>20:00</td>\n",
       "      <td>2016.10.02.0200</td>\n",
       "      <td>2016.10.02.0200</td>\n",
       "      <td>goes15.2016.10.02.0200.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.0200.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>03:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>21:00</td>\n",
       "      <td>2016.10.02.0300</td>\n",
       "      <td>2016.10.02.0300</td>\n",
       "      <td>goes15.2016.10.02.0300.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.0300.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>04:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>22:00</td>\n",
       "      <td>2016.10.02.0400</td>\n",
       "      <td>2016.10.02.0400</td>\n",
       "      <td>goes15.2016.10.02.0400.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.0400.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>05:00</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>23:00</td>\n",
       "      <td>2016.10.02.0500</td>\n",
       "      <td>2016.10.02.0500</td>\n",
       "      <td>goes15.2016.10.02.0500.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.0500.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>06:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2016.10.02.0600</td>\n",
       "      <td>2016.10.02.0600</td>\n",
       "      <td>goes15.2016.10.02.0600.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.0600.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>07:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>01:00</td>\n",
       "      <td>2016.10.02.0700</td>\n",
       "      <td>2016.10.02.0700</td>\n",
       "      <td>goes15.2016.10.02.0700.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.0700.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>08:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>02:00</td>\n",
       "      <td>2016.10.02.0800</td>\n",
       "      <td>2016.10.02.0800</td>\n",
       "      <td>goes15.2016.10.02.0800.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.0800.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>09:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>03:00</td>\n",
       "      <td>2016.10.02.0900</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>10:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>04:00</td>\n",
       "      <td>2016.10.02.1000</td>\n",
       "      <td>2016.10.02.1000</td>\n",
       "      <td>goes15.2016.10.02.1000.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.1000.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>11:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>05:00</td>\n",
       "      <td>2016.10.02.1100</td>\n",
       "      <td>2016.10.02.1100</td>\n",
       "      <td>goes15.2016.10.02.1100.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.1100.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>12:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>06:00</td>\n",
       "      <td>2016.10.02.1200</td>\n",
       "      <td>2016.10.02.1200</td>\n",
       "      <td>goes15.2016.10.02.1200.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.1200.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>13:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>07:00</td>\n",
       "      <td>2016.10.02.1300</td>\n",
       "      <td>2016.10.02.1300</td>\n",
       "      <td>goes15.2016.10.02.1300.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.1300.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>14:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>08:00</td>\n",
       "      <td>2016.10.02.1400</td>\n",
       "      <td>2016.10.02.1400</td>\n",
       "      <td>goes15.2016.10.02.1400.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.1400.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>15:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>09:00</td>\n",
       "      <td>2016.10.02.1500</td>\n",
       "      <td>2016.10.02.1500</td>\n",
       "      <td>goes15.2016.10.02.1500.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.1500.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>16:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>10:00</td>\n",
       "      <td>2016.10.02.1600</td>\n",
       "      <td>2016.10.02.1600</td>\n",
       "      <td>goes15.2016.10.02.1600.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.1600.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>17:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>11:00</td>\n",
       "      <td>2016.10.02.1700</td>\n",
       "      <td>2016.10.02.1700</td>\n",
       "      <td>goes15.2016.10.02.1700.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.1700.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>18:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>12:00</td>\n",
       "      <td>2016.10.02.1800</td>\n",
       "      <td>2016.10.02.1800</td>\n",
       "      <td>goes15.2016.10.02.1800.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.1800.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>13:00</td>\n",
       "      <td>2016.10.02.1900</td>\n",
       "      <td>2016.10.02.1900</td>\n",
       "      <td>goes15.2016.10.02.1900.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.1900.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>20:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>14:00</td>\n",
       "      <td>2016.10.02.2000</td>\n",
       "      <td>2016.10.02.2000</td>\n",
       "      <td>goes15.2016.10.02.2000.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.2000.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>21:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>15:00</td>\n",
       "      <td>2016.10.02.2100</td>\n",
       "      <td>2016.10.02.2100</td>\n",
       "      <td>goes15.2016.10.02.2100.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.2100.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>22:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>16:00</td>\n",
       "      <td>2016.10.02.2200</td>\n",
       "      <td>2016.10.02.2200</td>\n",
       "      <td>goes15.2016.10.02.2200.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.2200.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>23:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>17:00</td>\n",
       "      <td>2016.10.02.2300</td>\n",
       "      <td>2016.10.02.2300</td>\n",
       "      <td>goes15.2016.10.02.2300.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.02.2300.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>18:00</td>\n",
       "      <td>2016.10.03.0000</td>\n",
       "      <td>2016.10.03.0000</td>\n",
       "      <td>goes15.2016.10.03.0000.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.03.0000.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>01:00</td>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2016.10.03.0100</td>\n",
       "      <td>2016.10.03.0100</td>\n",
       "      <td>goes15.2016.10.03.0100.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.03.0100.v01.nc-var1-t0.csv.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date_UTC Time_UTC    Date_CST Time_CST intend_timestamp_list  \\\n",
       "0   2016-10-01    00:00  2016-09-30    18:00       2016.10.01.0000   \n",
       "1   2016-10-01    01:00  2016-09-30    19:00       2016.10.01.0100   \n",
       "2   2016-10-01    02:00  2016-09-30    20:00       2016.10.01.0200   \n",
       "3   2016-10-01    03:00  2016-09-30    21:00       2016.10.01.0300   \n",
       "4   2016-10-01    04:00  2016-09-30    22:00       2016.10.01.0400   \n",
       "5   2016-10-01    05:00  2016-09-30    23:00       2016.10.01.0500   \n",
       "6   2016-10-01    06:00  2016-10-01    00:00       2016.10.01.0600   \n",
       "7   2016-10-01    07:00  2016-10-01    01:00       2016.10.01.0700   \n",
       "8   2016-10-01    08:00  2016-10-01    02:00       2016.10.01.0800   \n",
       "9   2016-10-01    09:00  2016-10-01    03:00       2016.10.01.0900   \n",
       "10  2016-10-01    10:00  2016-10-01    04:00       2016.10.01.1000   \n",
       "11  2016-10-01    11:00  2016-10-01    05:00       2016.10.01.1100   \n",
       "12  2016-10-01    12:00  2016-10-01    06:00       2016.10.01.1200   \n",
       "13  2016-10-01    13:00  2016-10-01    07:00       2016.10.01.1300   \n",
       "14  2016-10-01    14:00  2016-10-01    08:00       2016.10.01.1400   \n",
       "15  2016-10-01    15:00  2016-10-01    09:00       2016.10.01.1500   \n",
       "16  2016-10-01    16:00  2016-10-01    10:00       2016.10.01.1600   \n",
       "17  2016-10-01    17:00  2016-10-01    11:00       2016.10.01.1700   \n",
       "18  2016-10-01    18:00  2016-10-01    12:00       2016.10.01.1800   \n",
       "19  2016-10-01    19:00  2016-10-01    13:00       2016.10.01.1900   \n",
       "20  2016-10-01    20:00  2016-10-01    14:00       2016.10.01.2000   \n",
       "21  2016-10-01    21:00  2016-10-01    15:00       2016.10.01.2100   \n",
       "22  2016-10-01    22:00  2016-10-01    16:00       2016.10.01.2200   \n",
       "23  2016-10-01    23:00  2016-10-01    17:00       2016.10.01.2300   \n",
       "24  2016-10-02    00:00  2016-10-01    18:00       2016.10.02.0000   \n",
       "25  2016-10-02    01:00  2016-10-01    19:00       2016.10.02.0100   \n",
       "26  2016-10-02    02:00  2016-10-01    20:00       2016.10.02.0200   \n",
       "27  2016-10-02    03:00  2016-10-01    21:00       2016.10.02.0300   \n",
       "28  2016-10-02    04:00  2016-10-01    22:00       2016.10.02.0400   \n",
       "29  2016-10-02    05:00  2016-10-01    23:00       2016.10.02.0500   \n",
       "30  2016-10-02    06:00  2016-10-02    00:00       2016.10.02.0600   \n",
       "31  2016-10-02    07:00  2016-10-02    01:00       2016.10.02.0700   \n",
       "32  2016-10-02    08:00  2016-10-02    02:00       2016.10.02.0800   \n",
       "33  2016-10-02    09:00  2016-10-02    03:00       2016.10.02.0900   \n",
       "34  2016-10-02    10:00  2016-10-02    04:00       2016.10.02.1000   \n",
       "35  2016-10-02    11:00  2016-10-02    05:00       2016.10.02.1100   \n",
       "36  2016-10-02    12:00  2016-10-02    06:00       2016.10.02.1200   \n",
       "37  2016-10-02    13:00  2016-10-02    07:00       2016.10.02.1300   \n",
       "38  2016-10-02    14:00  2016-10-02    08:00       2016.10.02.1400   \n",
       "39  2016-10-02    15:00  2016-10-02    09:00       2016.10.02.1500   \n",
       "40  2016-10-02    16:00  2016-10-02    10:00       2016.10.02.1600   \n",
       "41  2016-10-02    17:00  2016-10-02    11:00       2016.10.02.1700   \n",
       "42  2016-10-02    18:00  2016-10-02    12:00       2016.10.02.1800   \n",
       "43  2016-10-02    19:00  2016-10-02    13:00       2016.10.02.1900   \n",
       "44  2016-10-02    20:00  2016-10-02    14:00       2016.10.02.2000   \n",
       "45  2016-10-02    21:00  2016-10-02    15:00       2016.10.02.2100   \n",
       "46  2016-10-02    22:00  2016-10-02    16:00       2016.10.02.2200   \n",
       "47  2016-10-02    23:00  2016-10-02    17:00       2016.10.02.2300   \n",
       "48  2016-10-03    00:00  2016-10-02    18:00       2016.10.03.0000   \n",
       "49  2016-10-03    01:00  2016-10-02    19:00       2016.10.03.0100   \n",
       "\n",
       "     file_timestamp                               file_list_1D  \\\n",
       "0   2016.10.01.0000  goes15.2016.10.01.0000.v01.nc-var1-t0.csv   \n",
       "1   2016.10.01.0100  goes15.2016.10.01.0100.v01.nc-var1-t0.csv   \n",
       "2   2016.10.01.0200  goes15.2016.10.01.0200.v01.nc-var1-t0.csv   \n",
       "3   2016.10.01.0300  goes15.2016.10.01.0300.v01.nc-var1-t0.csv   \n",
       "4   2016.10.01.0400  goes15.2016.10.01.0400.v01.nc-var1-t0.csv   \n",
       "5   2016.10.01.0500  goes15.2016.10.01.0500.v01.nc-var1-t0.csv   \n",
       "6   2016.10.01.0600  goes15.2016.10.01.0600.v01.nc-var1-t0.csv   \n",
       "7   2016.10.01.0700  goes15.2016.10.01.0700.v01.nc-var1-t0.csv   \n",
       "8   2016.10.01.0800  goes15.2016.10.01.0800.v01.nc-var1-t0.csv   \n",
       "9   2016.10.01.0900  goes15.2016.10.01.0900.v01.nc-var1-t0.csv   \n",
       "10  2016.10.01.1000  goes15.2016.10.01.1000.v01.nc-var1-t0.csv   \n",
       "11  2016.10.01.1100  goes15.2016.10.01.1100.v01.nc-var1-t0.csv   \n",
       "12  2016.10.01.1200  goes15.2016.10.01.1200.v01.nc-var1-t0.csv   \n",
       "13  2016.10.01.1300  goes15.2016.10.01.1300.v01.nc-var1-t0.csv   \n",
       "14  2016.10.01.1400  goes15.2016.10.01.1400.v01.nc-var1-t0.csv   \n",
       "15  2016.10.01.1500  goes15.2016.10.01.1500.v01.nc-var1-t0.csv   \n",
       "16  2016.10.01.1600  goes15.2016.10.01.1600.v01.nc-var1-t0.csv   \n",
       "17  2016.10.01.1700  goes15.2016.10.01.1700.v01.nc-var1-t0.csv   \n",
       "18  2016.10.01.1800  goes15.2016.10.01.1800.v01.nc-var1-t0.csv   \n",
       "19  2016.10.01.1900  goes15.2016.10.01.1900.v01.nc-var1-t0.csv   \n",
       "20  2016.10.01.2000  goes15.2016.10.01.2000.v01.nc-var1-t0.csv   \n",
       "21  2016.10.01.2100  goes15.2016.10.01.2100.v01.nc-var1-t0.csv   \n",
       "22  2016.10.01.2200  goes15.2016.10.01.2200.v01.nc-var1-t0.csv   \n",
       "23  2016.10.01.2300  goes15.2016.10.01.2300.v01.nc-var1-t0.csv   \n",
       "24  2016.10.02.0000  goes15.2016.10.02.0000.v01.nc-var1-t0.csv   \n",
       "25  2016.10.02.0100  goes15.2016.10.02.0100.v01.nc-var1-t0.csv   \n",
       "26  2016.10.02.0200  goes15.2016.10.02.0200.v01.nc-var1-t0.csv   \n",
       "27  2016.10.02.0300  goes15.2016.10.02.0300.v01.nc-var1-t0.csv   \n",
       "28  2016.10.02.0400  goes15.2016.10.02.0400.v01.nc-var1-t0.csv   \n",
       "29  2016.10.02.0500  goes15.2016.10.02.0500.v01.nc-var1-t0.csv   \n",
       "30  2016.10.02.0600  goes15.2016.10.02.0600.v01.nc-var1-t0.csv   \n",
       "31  2016.10.02.0700  goes15.2016.10.02.0700.v01.nc-var1-t0.csv   \n",
       "32  2016.10.02.0800  goes15.2016.10.02.0800.v01.nc-var1-t0.csv   \n",
       "33             None                                       None   \n",
       "34  2016.10.02.1000  goes15.2016.10.02.1000.v01.nc-var1-t0.csv   \n",
       "35  2016.10.02.1100  goes15.2016.10.02.1100.v01.nc-var1-t0.csv   \n",
       "36  2016.10.02.1200  goes15.2016.10.02.1200.v01.nc-var1-t0.csv   \n",
       "37  2016.10.02.1300  goes15.2016.10.02.1300.v01.nc-var1-t0.csv   \n",
       "38  2016.10.02.1400  goes15.2016.10.02.1400.v01.nc-var1-t0.csv   \n",
       "39  2016.10.02.1500  goes15.2016.10.02.1500.v01.nc-var1-t0.csv   \n",
       "40  2016.10.02.1600  goes15.2016.10.02.1600.v01.nc-var1-t0.csv   \n",
       "41  2016.10.02.1700  goes15.2016.10.02.1700.v01.nc-var1-t0.csv   \n",
       "42  2016.10.02.1800  goes15.2016.10.02.1800.v01.nc-var1-t0.csv   \n",
       "43  2016.10.02.1900  goes15.2016.10.02.1900.v01.nc-var1-t0.csv   \n",
       "44  2016.10.02.2000  goes15.2016.10.02.2000.v01.nc-var1-t0.csv   \n",
       "45  2016.10.02.2100  goes15.2016.10.02.2100.v01.nc-var1-t0.csv   \n",
       "46  2016.10.02.2200  goes15.2016.10.02.2200.v01.nc-var1-t0.csv   \n",
       "47  2016.10.02.2300  goes15.2016.10.02.2300.v01.nc-var1-t0.csv   \n",
       "48  2016.10.03.0000  goes15.2016.10.03.0000.v01.nc-var1-t0.csv   \n",
       "49  2016.10.03.0100  goes15.2016.10.03.0100.v01.nc-var1-t0.csv   \n",
       "\n",
       "                                       file_list_2D  \n",
       "0   T_goes15.2016.10.01.0000.v01.nc-var1-t0.csv.csv  \n",
       "1   T_goes15.2016.10.01.0100.v01.nc-var1-t0.csv.csv  \n",
       "2   T_goes15.2016.10.01.0200.v01.nc-var1-t0.csv.csv  \n",
       "3   T_goes15.2016.10.01.0300.v01.nc-var1-t0.csv.csv  \n",
       "4   T_goes15.2016.10.01.0400.v01.nc-var1-t0.csv.csv  \n",
       "5   T_goes15.2016.10.01.0500.v01.nc-var1-t0.csv.csv  \n",
       "6   T_goes15.2016.10.01.0600.v01.nc-var1-t0.csv.csv  \n",
       "7   T_goes15.2016.10.01.0700.v01.nc-var1-t0.csv.csv  \n",
       "8   T_goes15.2016.10.01.0800.v01.nc-var1-t0.csv.csv  \n",
       "9   T_goes15.2016.10.01.0900.v01.nc-var1-t0.csv.csv  \n",
       "10  T_goes15.2016.10.01.1000.v01.nc-var1-t0.csv.csv  \n",
       "11  T_goes15.2016.10.01.1100.v01.nc-var1-t0.csv.csv  \n",
       "12  T_goes15.2016.10.01.1200.v01.nc-var1-t0.csv.csv  \n",
       "13  T_goes15.2016.10.01.1300.v01.nc-var1-t0.csv.csv  \n",
       "14  T_goes15.2016.10.01.1400.v01.nc-var1-t0.csv.csv  \n",
       "15  T_goes15.2016.10.01.1500.v01.nc-var1-t0.csv.csv  \n",
       "16  T_goes15.2016.10.01.1600.v01.nc-var1-t0.csv.csv  \n",
       "17  T_goes15.2016.10.01.1700.v01.nc-var1-t0.csv.csv  \n",
       "18  T_goes15.2016.10.01.1800.v01.nc-var1-t0.csv.csv  \n",
       "19  T_goes15.2016.10.01.1900.v01.nc-var1-t0.csv.csv  \n",
       "20  T_goes15.2016.10.01.2000.v01.nc-var1-t0.csv.csv  \n",
       "21  T_goes15.2016.10.01.2100.v01.nc-var1-t0.csv.csv  \n",
       "22  T_goes15.2016.10.01.2200.v01.nc-var1-t0.csv.csv  \n",
       "23  T_goes15.2016.10.01.2300.v01.nc-var1-t0.csv.csv  \n",
       "24  T_goes15.2016.10.02.0000.v01.nc-var1-t0.csv.csv  \n",
       "25  T_goes15.2016.10.02.0100.v01.nc-var1-t0.csv.csv  \n",
       "26  T_goes15.2016.10.02.0200.v01.nc-var1-t0.csv.csv  \n",
       "27  T_goes15.2016.10.02.0300.v01.nc-var1-t0.csv.csv  \n",
       "28  T_goes15.2016.10.02.0400.v01.nc-var1-t0.csv.csv  \n",
       "29  T_goes15.2016.10.02.0500.v01.nc-var1-t0.csv.csv  \n",
       "30  T_goes15.2016.10.02.0600.v01.nc-var1-t0.csv.csv  \n",
       "31  T_goes15.2016.10.02.0700.v01.nc-var1-t0.csv.csv  \n",
       "32  T_goes15.2016.10.02.0800.v01.nc-var1-t0.csv.csv  \n",
       "33                                             None  \n",
       "34  T_goes15.2016.10.02.1000.v01.nc-var1-t0.csv.csv  \n",
       "35  T_goes15.2016.10.02.1100.v01.nc-var1-t0.csv.csv  \n",
       "36  T_goes15.2016.10.02.1200.v01.nc-var1-t0.csv.csv  \n",
       "37  T_goes15.2016.10.02.1300.v01.nc-var1-t0.csv.csv  \n",
       "38  T_goes15.2016.10.02.1400.v01.nc-var1-t0.csv.csv  \n",
       "39  T_goes15.2016.10.02.1500.v01.nc-var1-t0.csv.csv  \n",
       "40  T_goes15.2016.10.02.1600.v01.nc-var1-t0.csv.csv  \n",
       "41  T_goes15.2016.10.02.1700.v01.nc-var1-t0.csv.csv  \n",
       "42  T_goes15.2016.10.02.1800.v01.nc-var1-t0.csv.csv  \n",
       "43  T_goes15.2016.10.02.1900.v01.nc-var1-t0.csv.csv  \n",
       "44  T_goes15.2016.10.02.2000.v01.nc-var1-t0.csv.csv  \n",
       "45  T_goes15.2016.10.02.2100.v01.nc-var1-t0.csv.csv  \n",
       "46  T_goes15.2016.10.02.2200.v01.nc-var1-t0.csv.csv  \n",
       "47  T_goes15.2016.10.02.2300.v01.nc-var1-t0.csv.csv  \n",
       "48  T_goes15.2016.10.03.0000.v01.nc-var1-t0.csv.csv  \n",
       "49  T_goes15.2016.10.03.0100.v01.nc-var1-t0.csv.csv  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GOES_combined = pd.merge(df_GOES_time_lib, df_GOES_file_lib, left_on='intend_timestamp_list', right_on='file_timestamp', how='left')\n",
    "df_GOES_combined.fillna('None', inplace=True)\n",
    "df_GOES_combined.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9cc82fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'output/GOES_file_lib_dir/'\n",
    "output_csv_name = str(start_year)+'Fall_'+str(end_year)+'Spring_GOES_lib.csv'\n",
    "\n",
    "output_file_path = os.path.join(output_dir, output_csv_name)\n",
    "\n",
    "df_GOES_combined.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0eeb2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Combine GOES Data Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e59fe700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corresponding row</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4891</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>2016-12-12 17:00:00</td>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4892</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>2016-12-12 17:00:00</td>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4893</td>\n",
       "      <td>0.4425</td>\n",
       "      <td>2016-12-12 17:00:00</td>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4894</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>2016-12-12 17:00:00</td>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4895</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>2016-12-12 17:00:00</td>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   corresponding row   value             datetime  latitude  longitude  \\\n",
       "0               4891  0.3500  2016-12-12 17:00:00     41.78     -87.54   \n",
       "1               4892  0.3500  2016-12-12 17:00:00     41.78     -87.50   \n",
       "2               4893  0.4425  2016-12-12 17:00:00     41.78     -87.46   \n",
       "3               4894  0.4350  2016-12-12 17:00:00     41.78     -87.42   \n",
       "4               4895  0.4600  2016-12-12 17:00:00     41.78     -87.38   \n",
       "\n",
       "   partition  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reference_1D = pd.read_csv('02-05-2023/zone_0_sample_take_2/' + 'goes15.2016.12.12.1700.v01.nc-var1-t0.csv')\n",
    "df_reference_1D.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08d2dfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3599\n"
     ]
    }
   ],
   "source": [
    "table_1D_len = df_reference_1D.shape[0]\n",
    "print(table_1D_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f03ac3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude\n",
       "0     41.78     -87.54\n",
       "1     41.78     -87.50\n",
       "2     41.78     -87.46\n",
       "3     41.78     -87.42\n",
       "4     41.78     -87.38"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lake_1D_map = df_reference_1D[['latitude', 'longitude']].copy()\n",
    "df_lake_1D_map.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e980d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat_list = df_lake_1D_map['latitude'].tolist()\n",
    "# lon_list = df_lake_1D_map['longitude'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94987c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = 'output/'\n",
    "# output_csv_name = 'lat_long_1D_labels_for_plotting.csv'\n",
    "\n",
    "# output_file_path = os.path.join(output_dir, output_csv_name)\n",
    "\n",
    "# df_lake_1D_map.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3bddac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lake_1D_matcher(df_temp, df_lake_1D_map):\n",
    "    # left join df_temp with df_lake_1D_map based on latitude and longitude\n",
    "    df_merged_temp = pd.merge(df_lake_1D_map, df_temp, on=['latitude', 'longitude'], how='left')\n",
    "\n",
    "    # extract value column into a list\n",
    "    value_temp = df_merged_temp['value'].tolist()\n",
    "\n",
    "    return value_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9506d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_1D_file_list = df_GOES_combined['file_list_1D'].tolist()\n",
    "matched_1D_file_list[:50]\n",
    "matched_2D_file_list = df_GOES_combined['file_list_2D'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce671af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3599"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = df_reference_1D.values\n",
    "len(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1661f147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corresponding row</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5360</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2016-12-08 12:00:00</td>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5361</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2016-12-08 12:00:00</td>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5362</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2016-12-08 12:00:00</td>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5363</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2016-12-08 12:00:00</td>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5364</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2016-12-08 12:00:00</td>\n",
       "      <td>41.78</td>\n",
       "      <td>-87.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   corresponding row   value             datetime  latitude  longitude  \\\n",
       "0               5360  0.0025  2016-12-08 12:00:00     41.78     -87.54   \n",
       "1               5361  0.0025  2016-12-08 12:00:00     41.78     -87.50   \n",
       "2               5362  0.0025  2016-12-08 12:00:00     41.78     -87.46   \n",
       "3               5363  0.0000  2016-12-08 12:00:00     41.78     -87.42   \n",
       "4               5364  0.0000  2016-12-08 12:00:00     41.78     -87.38   \n",
       "\n",
       "   partition  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tester_again = pd.read_csv('02-05-2023/zone_0_sample_take_2/' + 'goes15.2016.12.08.1200.v01.nc-var1-t0.csv')\n",
    "df_tester_again.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e45670f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0025,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.005,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " 0.0075,\n",
       " 0.005,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.005,\n",
       " 0.005,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.005,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0075,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.005,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.005,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.005,\n",
       " 0.005,\n",
       " nan,\n",
       " nan,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0075,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0075,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0075,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0075,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.005,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0075,\n",
       " 0.0,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0075,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0075,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " 0.01,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0075,\n",
       " 0.005,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0075,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.005,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0075,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0075,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0075,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0075,\n",
       " nan,\n",
       " nan,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0,\n",
       " 0.0075,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.005,\n",
       " nan,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.005,\n",
       " 0.005,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " 0.01,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.005,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0075,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0075,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.005,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0075,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0075,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0075,\n",
       " 0.0,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.01,\n",
       " 0.005,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0075,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0075,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.005,\n",
       " nan,\n",
       " nan,\n",
       " 0.005,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0075,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.005,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.01,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0075,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0075,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0075,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0075,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0075,\n",
       " 0.0075,\n",
       " nan,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.005,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.005,\n",
       " 0.005,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.005,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0075,\n",
       " 0.0,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.005,\n",
       " 0.0075,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.005,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0075,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " nan,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " nan,\n",
       " 0.0025,\n",
       " 0.01,\n",
       " 0.0,\n",
       " 0.0025,\n",
       " 0.0025,\n",
       " 0.005,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0075,\n",
       " 0.0025,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_result_tester = lake_1D_matcher(df_tester_again, df_lake_1D_map)\n",
    "temp_result_tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f85920d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3599"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_result_tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6223c190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e389ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_data(df_temp):\n",
    "    \n",
    "    crit_1 = 0\n",
    "    crit_2 = 0\n",
    "    crit_3 = 0\n",
    "        \n",
    "    # Pass in value\n",
    "    i_temp = df_temp.value\n",
    "    \n",
    "\n",
    "    try:\n",
    "        \n",
    "        i_temp_max = i_temp.max().max()\n",
    "\n",
    "        # Acquire mode in the array\n",
    "        i_temp_mode = i_temp.mode()[0]\n",
    "    except:\n",
    "        i_temp_max = 0\n",
    "        i_temp_mode = 0\n",
    "    \n",
    "    # Check Criteria #1:\n",
    "    if i_temp_max <= 0.03:\n",
    "        crit_1 = 1\n",
    "    \n",
    "    # Check Criteria #2:\n",
    "    if i_temp_mode <= 0.02:\n",
    "        crit_2 = 1\n",
    "    \n",
    "    # Check Criteria #3\n",
    "    if len(i_temp) <= 3000:\n",
    "        crit_3 = 1\n",
    "        \n",
    "    crit_sum = crit_1 + crit_2 + crit_3\n",
    "    \n",
    "    if crit_sum > 0:\n",
    "        cond = False\n",
    "    else:\n",
    "        cond = True\n",
    "        \n",
    "    return cond\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1654deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloud_finder(value_temp):\n",
    "    # Deduct 0.1 from all elements in the array\n",
    "    value_temp = [x - 0.1 for x in value_temp]\n",
    "    \n",
    "    # Count the number of elements that are larger than or equal to 0\n",
    "    count = sum(1 for x in value_temp if x >= 0)\n",
    "    \n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63960e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2e730c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf940e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee71c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ddc785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111440f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7d62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf232a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4368/4368 [00:31<00:00, 137.18it/s]\n"
     ]
    }
   ],
   "source": [
    "lake_1D_list = []\n",
    "# lat_lists = []\n",
    "# lon_lists = []\n",
    "cond_list = []\n",
    "count_list = []\n",
    "cloud_exist_list = []\n",
    "\n",
    "\n",
    "# counter = 1\n",
    "for file_name in tqdm(matched_1D_file_list):\n",
    "# for file_name in matched_1D_file_list[1769:1775]:\n",
    "    \n",
    "    try:\n",
    "        temp_file_path = parent_path + folder_name + '/' + file_name\n",
    "#         print( temp_file_path)\n",
    "#         print(counter)\n",
    "        df_temp = pd.read_csv(temp_file_path)\n",
    "        value_temp = lake_1D_matcher(df_temp, df_lake_1D_map)\n",
    "        cond = is_valid_data(df_temp)\n",
    "        cond_list.append(cond)\n",
    "        lake_1D_list.append(value_temp)\n",
    "        num_clouds = cloud_finder(value_temp)\n",
    "        count_list.append(num_clouds) \n",
    "        if num_clouds < 720:\n",
    "            exist_temp = False\n",
    "        else:\n",
    "            exist_temp = True\n",
    "        # Replace all NaN values in the 'exist_temp' array with 0.0\n",
    "        exist_temp = np.nan_to_num(exist_temp, nan=0.0)\n",
    "        cloud_exist_list.append(exist_temp)\n",
    "#         lat_lists.append(lat_list)\n",
    "#         lon_lists.append(lon_list)\n",
    "    except FileNotFoundError:\n",
    "        lake_1D_list.append(np.zeros(3599))\n",
    "        cond_list.append(False)\n",
    "        count_list.append(0) \n",
    "        cloud_exist_list.append(False)\n",
    "#         lat_lists.append([np.nan]*table_1D_len)\n",
    "#         lon_lists.append([np.nan]*table_1D_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a086507b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of entries in result =  4368\n",
      "# of entries in result =  4368\n",
      "# of entries in result =  4368\n",
      "# of entries in result =  4368\n",
      "# of entries in dataframe =  4368\n"
     ]
    }
   ],
   "source": [
    "# lake_1D_list[15]\n",
    "print('# of entries in result = ', len(lake_1D_list))\n",
    "print('# of entries in result = ', len(cond_list))\n",
    "print('# of entries in result = ', len(count_list))\n",
    "print('# of entries in result = ', len(cloud_exist_list))\n",
    "print('# of entries in dataframe = ', df_GOES_combined.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e92586cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4368/4368 [00:14<00:00, 310.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# list of matrices\n",
    "lake_2D_list = []\n",
    "\n",
    "# loop over file names\n",
    "for file_name in tqdm(matched_2D_file_list):\n",
    "    try:\n",
    "        # read csv file into dataframe\n",
    "        temp_file_path = parent_path + folder_name_2D + '/' + file_name\n",
    "        df_temp = pd.read_csv(temp_file_path)\n",
    "        df_temp = df_temp.iloc[1:, 1:]\n",
    "        # Replace NaN values in 'values' with 0 in 'df_temp'\n",
    "        df_temp = df_temp.fillna(0)\n",
    "#         print(df_temp.shape)\n",
    "        # convert dataframe to numpy array/matrix\n",
    "        mat_temp = df_temp.values\n",
    "#         mat_temp = np.array(df_temp.values.flatten())\n",
    "\n",
    "        # assume df_temp is a DataFrame with multiple columns\n",
    "#         arrays = [df_temp.iloc[:, i].to_numpy() for i in range(len(df_temp.columns))]\n",
    "#         mat_temp = arrays\n",
    "    except FileNotFoundError:\n",
    "        # if file does not exist, save NaN\n",
    "        mat_temp = np.zeros((105, 79))\n",
    "    \n",
    "    # append matrix to list\n",
    "    lake_2D_list.append(mat_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "384b8756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of entries in result =  4368\n",
      "# of entries in dataframe =  4368\n"
     ]
    }
   ],
   "source": [
    "# lake_2D_list[15][20]\n",
    "\n",
    "print('# of entries in result = ', len(lake_2D_list))\n",
    "print('# of entries in dataframe = ', df_GOES_combined.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2555c5e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Merger\n",
    "\n",
    "Now, it is time to merge the weather station data into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e94977b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_GOES_combined['latitude_1D_label'] = lat_lists\n",
    "# df_GOES_combined['longitude_1D_label'] = lon_lists\n",
    "# cond_list = []\n",
    "# count_list = []\n",
    "# cloud_exist_list = []\n",
    "\n",
    "df_GOES_combined['lake_1D_list'] = lake_1D_list\n",
    "df_GOES_combined['lake_2D_list'] = lake_2D_list\n",
    "df_GOES_combined['data_usable'] = cond_list\n",
    "df_GOES_combined['cloud_count'] = count_list\n",
    "df_GOES_combined['cloud_exist'] = cloud_exist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2376e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_UTC</th>\n",
       "      <th>Time_UTC</th>\n",
       "      <th>Date_CST</th>\n",
       "      <th>Time_CST</th>\n",
       "      <th>intend_timestamp_list</th>\n",
       "      <th>file_timestamp</th>\n",
       "      <th>file_list_1D</th>\n",
       "      <th>file_list_2D</th>\n",
       "      <th>lake_1D_list</th>\n",
       "      <th>lake_2D_list</th>\n",
       "      <th>data_usable</th>\n",
       "      <th>cloud_count</th>\n",
       "      <th>cloud_exist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>18:00</td>\n",
       "      <td>2016.10.01.0000</td>\n",
       "      <td>2016.10.01.0000</td>\n",
       "      <td>goes15.2016.10.01.0000.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0000.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[0.0025, 0.005, nan, 0.0025, nan, 0.005, nan, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>01:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2016.10.01.0100</td>\n",
       "      <td>2016.10.01.0100</td>\n",
       "      <td>goes15.2016.10.01.0100.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0100.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.005, nan, nan, 0.0025, 0.01,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>02:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>20:00</td>\n",
       "      <td>2016.10.01.0200</td>\n",
       "      <td>2016.10.01.0200</td>\n",
       "      <td>goes15.2016.10.01.0200.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0200.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[0.005, 0.0025, nan, 0.0, 0.0, 0.0, 0.0025, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>03:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>21:00</td>\n",
       "      <td>2016.10.01.0300</td>\n",
       "      <td>2016.10.01.0300</td>\n",
       "      <td>goes15.2016.10.01.0300.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0300.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[0.0025, nan, 0.0, 0.0025, 0.005, 0.0, 0.005, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>04:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>22:00</td>\n",
       "      <td>2016.10.01.0400</td>\n",
       "      <td>2016.10.01.0400</td>\n",
       "      <td>goes15.2016.10.01.0400.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0400.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[nan, nan, nan, 0.0, 0.0, 0.0, 0.0025, 0.0, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date_UTC Time_UTC    Date_CST Time_CST intend_timestamp_list  \\\n",
       "0  2016-10-01    00:00  2016-09-30    18:00       2016.10.01.0000   \n",
       "1  2016-10-01    01:00  2016-09-30    19:00       2016.10.01.0100   \n",
       "2  2016-10-01    02:00  2016-09-30    20:00       2016.10.01.0200   \n",
       "3  2016-10-01    03:00  2016-09-30    21:00       2016.10.01.0300   \n",
       "4  2016-10-01    04:00  2016-09-30    22:00       2016.10.01.0400   \n",
       "\n",
       "    file_timestamp                               file_list_1D  \\\n",
       "0  2016.10.01.0000  goes15.2016.10.01.0000.v01.nc-var1-t0.csv   \n",
       "1  2016.10.01.0100  goes15.2016.10.01.0100.v01.nc-var1-t0.csv   \n",
       "2  2016.10.01.0200  goes15.2016.10.01.0200.v01.nc-var1-t0.csv   \n",
       "3  2016.10.01.0300  goes15.2016.10.01.0300.v01.nc-var1-t0.csv   \n",
       "4  2016.10.01.0400  goes15.2016.10.01.0400.v01.nc-var1-t0.csv   \n",
       "\n",
       "                                      file_list_2D  \\\n",
       "0  T_goes15.2016.10.01.0000.v01.nc-var1-t0.csv.csv   \n",
       "1  T_goes15.2016.10.01.0100.v01.nc-var1-t0.csv.csv   \n",
       "2  T_goes15.2016.10.01.0200.v01.nc-var1-t0.csv.csv   \n",
       "3  T_goes15.2016.10.01.0300.v01.nc-var1-t0.csv.csv   \n",
       "4  T_goes15.2016.10.01.0400.v01.nc-var1-t0.csv.csv   \n",
       "\n",
       "                                        lake_1D_list  \\\n",
       "0  [0.0025, 0.005, nan, 0.0025, nan, 0.005, nan, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.005, nan, nan, 0.0025, 0.01,...   \n",
       "2  [0.005, 0.0025, nan, 0.0, 0.0, 0.0, 0.0025, 0....   \n",
       "3  [0.0025, nan, 0.0, 0.0025, 0.005, 0.0, 0.005, ...   \n",
       "4  [nan, nan, nan, 0.0, 0.0, 0.0, 0.0025, 0.0, 0....   \n",
       "\n",
       "                                        lake_2D_list  data_usable  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        False   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        False   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        False   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        False   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        False   \n",
       "\n",
       "   cloud_count  cloud_exist  \n",
       "0            0        False  \n",
       "1            0        False  \n",
       "2            0        False  \n",
       "3            0        False  \n",
       "4            0        False  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GOES_combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "578468c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_UTC</th>\n",
       "      <th>Time_UTC</th>\n",
       "      <th>Date_CST</th>\n",
       "      <th>Time_CST</th>\n",
       "      <th>intend_timestamp_list</th>\n",
       "      <th>file_timestamp</th>\n",
       "      <th>file_list_1D</th>\n",
       "      <th>file_list_2D</th>\n",
       "      <th>lake_1D_list</th>\n",
       "      <th>lake_2D_list</th>\n",
       "      <th>...</th>\n",
       "      <th>Med Cloud Ht (ft)</th>\n",
       "      <th>High Cloud Ht (ft)</th>\n",
       "      <th>Visibility (mi)</th>\n",
       "      <th>Atm Press (hPa)</th>\n",
       "      <th>Sea Lev Press (hPa)</th>\n",
       "      <th>Altimeter (hPa)</th>\n",
       "      <th>Precip (in)</th>\n",
       "      <th>Wind Chill (F)</th>\n",
       "      <th>Heat Index (F)</th>\n",
       "      <th>is_snow_precip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>18:00</td>\n",
       "      <td>2016.10.01.0000</td>\n",
       "      <td>2016.10.01.0000</td>\n",
       "      <td>goes15.2016.10.01.0000.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0000.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[0.0025, 0.005, nan, 0.0025, nan, 0.005, nan, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>...</td>\n",
       "      <td>9000</td>\n",
       "      <td>15000</td>\n",
       "      <td>10</td>\n",
       "      <td>999.30</td>\n",
       "      <td>1022.10</td>\n",
       "      <td>1022.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>01:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2016.10.01.0100</td>\n",
       "      <td>2016.10.01.0100</td>\n",
       "      <td>goes15.2016.10.01.0100.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0100.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.005, nan, nan, 0.0025, 0.01,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>...</td>\n",
       "      <td>11000</td>\n",
       "      <td>m</td>\n",
       "      <td>10</td>\n",
       "      <td>999.30</td>\n",
       "      <td>1022.30</td>\n",
       "      <td>1022.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>02:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>20:00</td>\n",
       "      <td>2016.10.01.0200</td>\n",
       "      <td>2016.10.01.0200</td>\n",
       "      <td>goes15.2016.10.01.0200.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0200.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[0.005, 0.0025, nan, 0.0, 0.0, 0.0, 0.0025, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>...</td>\n",
       "      <td>11000</td>\n",
       "      <td>m</td>\n",
       "      <td>10</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1022.10</td>\n",
       "      <td>1022.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>03:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>21:00</td>\n",
       "      <td>2016.10.01.0300</td>\n",
       "      <td>2016.10.01.0300</td>\n",
       "      <td>goes15.2016.10.01.0300.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0300.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[0.0025, nan, 0.0, 0.0025, 0.005, 0.0, 0.005, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>10</td>\n",
       "      <td>999.30</td>\n",
       "      <td>1022.30</td>\n",
       "      <td>1022.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>04:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>22:00</td>\n",
       "      <td>2016.10.01.0400</td>\n",
       "      <td>2016.10.01.0400</td>\n",
       "      <td>goes15.2016.10.01.0400.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0400.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[nan, nan, nan, 0.0, 0.0, 0.0, 0.0025, 0.0, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>...</td>\n",
       "      <td>11000</td>\n",
       "      <td>m</td>\n",
       "      <td>10</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1022.10</td>\n",
       "      <td>1022.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date_UTC Time_UTC    Date_CST Time_CST intend_timestamp_list  \\\n",
       "0  2016-10-01    00:00  2016-09-30    18:00       2016.10.01.0000   \n",
       "1  2016-10-01    01:00  2016-09-30    19:00       2016.10.01.0100   \n",
       "2  2016-10-01    02:00  2016-09-30    20:00       2016.10.01.0200   \n",
       "3  2016-10-01    03:00  2016-09-30    21:00       2016.10.01.0300   \n",
       "4  2016-10-01    04:00  2016-09-30    22:00       2016.10.01.0400   \n",
       "\n",
       "    file_timestamp                               file_list_1D  \\\n",
       "0  2016.10.01.0000  goes15.2016.10.01.0000.v01.nc-var1-t0.csv   \n",
       "1  2016.10.01.0100  goes15.2016.10.01.0100.v01.nc-var1-t0.csv   \n",
       "2  2016.10.01.0200  goes15.2016.10.01.0200.v01.nc-var1-t0.csv   \n",
       "3  2016.10.01.0300  goes15.2016.10.01.0300.v01.nc-var1-t0.csv   \n",
       "4  2016.10.01.0400  goes15.2016.10.01.0400.v01.nc-var1-t0.csv   \n",
       "\n",
       "                                      file_list_2D  \\\n",
       "0  T_goes15.2016.10.01.0000.v01.nc-var1-t0.csv.csv   \n",
       "1  T_goes15.2016.10.01.0100.v01.nc-var1-t0.csv.csv   \n",
       "2  T_goes15.2016.10.01.0200.v01.nc-var1-t0.csv.csv   \n",
       "3  T_goes15.2016.10.01.0300.v01.nc-var1-t0.csv.csv   \n",
       "4  T_goes15.2016.10.01.0400.v01.nc-var1-t0.csv.csv   \n",
       "\n",
       "                                        lake_1D_list  \\\n",
       "0  [0.0025, 0.005, nan, 0.0025, nan, 0.005, nan, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.005, nan, nan, 0.0025, 0.01,...   \n",
       "2  [0.005, 0.0025, nan, 0.0, 0.0, 0.0, 0.0025, 0....   \n",
       "3  [0.0025, nan, 0.0, 0.0025, 0.005, 0.0, 0.005, ...   \n",
       "4  [nan, nan, nan, 0.0, 0.0, 0.0, 0.0025, 0.0, 0....   \n",
       "\n",
       "                                        lake_2D_list  ...  Med Cloud Ht (ft)  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  ...               9000   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  ...              11000   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  ...              11000   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  ...                  m   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  ...              11000   \n",
       "\n",
       "   High Cloud Ht (ft)  Visibility (mi) Atm Press (hPa) Sea Lev Press (hPa)  \\\n",
       "0               15000               10          999.30             1022.10   \n",
       "1                   m               10          999.30             1022.30   \n",
       "2                   m               10          999.00             1022.10   \n",
       "3                   m               10          999.30             1022.30   \n",
       "4                   m               10          999.00             1022.10   \n",
       "\n",
       "   Altimeter (hPa) Precip (in)  Wind Chill (F) Heat Index (F) is_snow_precip  \n",
       "0          1022.40        0.00              NC             NC          False  \n",
       "1          1022.40        0.00              NC             NC          False  \n",
       "2          1022.00        0.01              NC             NC          False  \n",
       "3          1022.40        0.00              NC             NC          False  \n",
       "4          1022.00        0.00              NC             NC          False  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GOES_meteo_combined = pd.merge(df_GOES_combined, weather_with_CST, on=['Date_CST', 'Time_CST'], how='left')\n",
    "df_GOES_meteo_combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79dfec95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date_UTC', 'Time_UTC', 'Date_CST', 'Time_CST', 'intend_timestamp_list', 'file_timestamp', 'file_list_1D', 'file_list_2D', 'lake_1D_list', 'lake_2D_list', 'data_usable', 'cloud_count', 'cloud_exist', 'Date', 'Time', 'Temp (F)', 'RH (%)', 'Dewpt (F)', 'Wind Spd (mph)', 'Wind Direction (deg)', 'Peak Wind Gust(mph)', 'Low Cloud Ht (ft)', 'Med Cloud Ht (ft)', 'High Cloud Ht (ft)', 'Visibility (mi)', 'Atm Press (hPa)', 'Sea Lev Press (hPa)', 'Altimeter (hPa)', 'Precip (in)', 'Wind Chill (F)', 'Heat Index (F)', 'is_snow_precip']\n"
     ]
    }
   ],
   "source": [
    "column_names = df_GOES_meteo_combined.columns.tolist()\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "857a6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOES_meteo_combined = df_GOES_meteo_combined.drop(['Date', 'Time', 'intend_timestamp_list', 'file_timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3de2970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOES_meteo_combined.rename(columns={'file_list_1D': 'File_name_for_1D_lake'}, inplace=True)\n",
    "df_GOES_meteo_combined.rename(columns={'file_list_2D': 'File_name_for_2D_lake'}, inplace=True)\n",
    "df_GOES_meteo_combined.rename(columns={'lake_1D_list': 'Lake_data_1D'}, inplace=True)\n",
    "df_GOES_meteo_combined.rename(columns={'lake_2D_list': 'Lake_data_2D'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bae9ec94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_UTC</th>\n",
       "      <th>Time_UTC</th>\n",
       "      <th>Date_CST</th>\n",
       "      <th>Time_CST</th>\n",
       "      <th>File_name_for_1D_lake</th>\n",
       "      <th>File_name_for_2D_lake</th>\n",
       "      <th>Lake_data_1D</th>\n",
       "      <th>Lake_data_2D</th>\n",
       "      <th>data_usable</th>\n",
       "      <th>cloud_count</th>\n",
       "      <th>...</th>\n",
       "      <th>Med Cloud Ht (ft)</th>\n",
       "      <th>High Cloud Ht (ft)</th>\n",
       "      <th>Visibility (mi)</th>\n",
       "      <th>Atm Press (hPa)</th>\n",
       "      <th>Sea Lev Press (hPa)</th>\n",
       "      <th>Altimeter (hPa)</th>\n",
       "      <th>Precip (in)</th>\n",
       "      <th>Wind Chill (F)</th>\n",
       "      <th>Heat Index (F)</th>\n",
       "      <th>is_snow_precip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>18:00</td>\n",
       "      <td>goes15.2016.10.01.0000.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0000.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[0.0025, 0.005, nan, 0.0025, nan, 0.005, nan, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9000</td>\n",
       "      <td>15000</td>\n",
       "      <td>10</td>\n",
       "      <td>999.30</td>\n",
       "      <td>1022.10</td>\n",
       "      <td>1022.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>01:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>19:00</td>\n",
       "      <td>goes15.2016.10.01.0100.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0100.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.005, nan, nan, 0.0025, 0.01,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11000</td>\n",
       "      <td>m</td>\n",
       "      <td>10</td>\n",
       "      <td>999.30</td>\n",
       "      <td>1022.30</td>\n",
       "      <td>1022.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>02:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>20:00</td>\n",
       "      <td>goes15.2016.10.01.0200.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0200.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[0.005, 0.0025, nan, 0.0, 0.0, 0.0, 0.0025, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11000</td>\n",
       "      <td>m</td>\n",
       "      <td>10</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1022.10</td>\n",
       "      <td>1022.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>03:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>21:00</td>\n",
       "      <td>goes15.2016.10.01.0300.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0300.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[0.0025, nan, 0.0, 0.0025, 0.005, 0.0, 0.005, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>10</td>\n",
       "      <td>999.30</td>\n",
       "      <td>1022.30</td>\n",
       "      <td>1022.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>04:00</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>22:00</td>\n",
       "      <td>goes15.2016.10.01.0400.v01.nc-var1-t0.csv</td>\n",
       "      <td>T_goes15.2016.10.01.0400.v01.nc-var1-t0.csv.csv</td>\n",
       "      <td>[nan, nan, nan, 0.0, 0.0, 0.0, 0.0025, 0.0, 0....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11000</td>\n",
       "      <td>m</td>\n",
       "      <td>10</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1022.10</td>\n",
       "      <td>1022.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date_UTC Time_UTC    Date_CST Time_CST  \\\n",
       "0  2016-10-01    00:00  2016-09-30    18:00   \n",
       "1  2016-10-01    01:00  2016-09-30    19:00   \n",
       "2  2016-10-01    02:00  2016-09-30    20:00   \n",
       "3  2016-10-01    03:00  2016-09-30    21:00   \n",
       "4  2016-10-01    04:00  2016-09-30    22:00   \n",
       "\n",
       "                       File_name_for_1D_lake  \\\n",
       "0  goes15.2016.10.01.0000.v01.nc-var1-t0.csv   \n",
       "1  goes15.2016.10.01.0100.v01.nc-var1-t0.csv   \n",
       "2  goes15.2016.10.01.0200.v01.nc-var1-t0.csv   \n",
       "3  goes15.2016.10.01.0300.v01.nc-var1-t0.csv   \n",
       "4  goes15.2016.10.01.0400.v01.nc-var1-t0.csv   \n",
       "\n",
       "                             File_name_for_2D_lake  \\\n",
       "0  T_goes15.2016.10.01.0000.v01.nc-var1-t0.csv.csv   \n",
       "1  T_goes15.2016.10.01.0100.v01.nc-var1-t0.csv.csv   \n",
       "2  T_goes15.2016.10.01.0200.v01.nc-var1-t0.csv.csv   \n",
       "3  T_goes15.2016.10.01.0300.v01.nc-var1-t0.csv.csv   \n",
       "4  T_goes15.2016.10.01.0400.v01.nc-var1-t0.csv.csv   \n",
       "\n",
       "                                        Lake_data_1D  \\\n",
       "0  [0.0025, 0.005, nan, 0.0025, nan, 0.005, nan, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.005, nan, nan, 0.0025, 0.01,...   \n",
       "2  [0.005, 0.0025, nan, 0.0, 0.0, 0.0, 0.0025, 0....   \n",
       "3  [0.0025, nan, 0.0, 0.0025, 0.005, 0.0, 0.005, ...   \n",
       "4  [nan, nan, nan, 0.0, 0.0, 0.0, 0.0025, 0.0, 0....   \n",
       "\n",
       "                                        Lake_data_2D  data_usable  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        False   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        False   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        False   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        False   \n",
       "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...        False   \n",
       "\n",
       "   cloud_count  ...  Med Cloud Ht (ft)  High Cloud Ht (ft) Visibility (mi)  \\\n",
       "0            0  ...               9000               15000              10   \n",
       "1            0  ...              11000                   m              10   \n",
       "2            0  ...              11000                   m              10   \n",
       "3            0  ...                  m                   m              10   \n",
       "4            0  ...              11000                   m              10   \n",
       "\n",
       "   Atm Press (hPa) Sea Lev Press (hPa) Altimeter (hPa) Precip (in)  \\\n",
       "0           999.30             1022.10         1022.40        0.00   \n",
       "1           999.30             1022.30         1022.40        0.00   \n",
       "2           999.00             1022.10         1022.00        0.01   \n",
       "3           999.30             1022.30         1022.40        0.00   \n",
       "4           999.00             1022.10         1022.00        0.00   \n",
       "\n",
       "  Wind Chill (F) Heat Index (F) is_snow_precip  \n",
       "0             NC             NC          False  \n",
       "1             NC             NC          False  \n",
       "2             NC             NC          False  \n",
       "3             NC             NC          False  \n",
       "4             NC             NC          False  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GOES_meteo_combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c80e0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date_UTC', 'Time_UTC', 'Date_CST', 'Time_CST', 'File_name_for_1D_lake', 'File_name_for_2D_lake', 'Lake_data_1D', 'Lake_data_2D', 'data_usable', 'cloud_count', 'cloud_exist', 'Temp (F)', 'RH (%)', 'Dewpt (F)', 'Wind Spd (mph)', 'Wind Direction (deg)', 'Peak Wind Gust(mph)', 'Low Cloud Ht (ft)', 'Med Cloud Ht (ft)', 'High Cloud Ht (ft)', 'Visibility (mi)', 'Atm Press (hPa)', 'Sea Lev Press (hPa)', 'Altimeter (hPa)', 'Precip (in)', 'Wind Chill (F)', 'Heat Index (F)', 'is_snow_precip']\n"
     ]
    }
   ],
   "source": [
    "column_names = df_GOES_meteo_combined.columns.tolist()\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "187ea294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = 'output/exp2/'\n",
    "# output_csv_name = str(start_year)+'Fall_'+str(end_year)+'Spring_GOES_meteo_combined.csv'\n",
    "\n",
    "# output_file_path = os.path.join(output_dir, output_csv_name)\n",
    "\n",
    "# df_GOES_meteo_combined.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "82753e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_GOES_meteo_combined[df_GOES_meteo_combined['Precip (in)']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea92ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea9bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff3b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfd5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962f654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "21967caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOES_meteo_combined_all = df_GOES_meteo_combined.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "21ccc2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_142696/2254972987.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_GOES_meteo_combined_all = df_GOES_meteo_combined_all.append(df_GOES_meteo_combined, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_GOES_meteo_combined_all = df_GOES_meteo_combined_all.append(df_GOES_meteo_combined, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2a928c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48048, 28)\n"
     ]
    }
   ],
   "source": [
    "print(df_GOES_meteo_combined_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "91e142c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4368, 28)\n"
     ]
    }
   ],
   "source": [
    "print(df_GOES_meteo_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f44f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa2fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a9a684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572dfe4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1144ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35e25d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3908c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window size\n",
    "window_size = 8\n",
    "\n",
    "# Calculate the rolling sum of the column 'Precip (in)'\n",
    "precip_sum = df_GOES_meteo_combined['Precip (in)'].rolling(window_size).sum()\n",
    "\n",
    "# Shift the rolling sum by the window size to get the sum of the next 8 rows\n",
    "precip_8_hr = precip_sum.shift(-window_size)\n",
    "\n",
    "# Convert the result to a list\n",
    "Precip_8_Hr = precip_8_hr.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f4cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3533db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa65ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4453005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8432961b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4368"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Precip_8_Hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "df74a13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02,\n",
       " 0.02,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.01,\n",
       " 0.05,\n",
       " 0.060000000000000005,\n",
       " 0.060000000000000005,\n",
       " 0.09,\n",
       " 0.16,\n",
       " 0.17,\n",
       " 0.17,\n",
       " 0.16,\n",
       " 0.12,\n",
       " 0.11,\n",
       " 0.11,\n",
       " 0.07999999999999999,\n",
       " 0.009999999999999986,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.03999999999999999,\n",
       " 0.04999999999999999,\n",
       " 0.059999999999999984,\n",
       " 0.10999999999999999,\n",
       " 0.10999999999999999,\n",
       " 0.10999999999999999,\n",
       " 0.10999999999999999,\n",
       " 0.10999999999999999,\n",
       " 0.06999999999999998,\n",
       " 0.059999999999999984,\n",
       " 0.04999999999999999,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.15999999999999998,\n",
       " 0.16,\n",
       " 0.16,\n",
       " 0.16,\n",
       " 0.16,\n",
       " 0.16,\n",
       " 0.16,\n",
       " 0.16,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.01,\n",
       " 0.09,\n",
       " 0.28,\n",
       " 0.45999999999999996,\n",
       " 0.45999999999999996,\n",
       " 0.47,\n",
       " 0.5,\n",
       " 0.53,\n",
       " 0.52,\n",
       " 0.44,\n",
       " 0.29,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.12000000000000001,\n",
       " 0.09,\n",
       " 0.06,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.03,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.02,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.13,\n",
       " 0.11,\n",
       " 0.11,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.45,\n",
       " 0.47000000000000003,\n",
       " 0.48000000000000004,\n",
       " 0.48000000000000004,\n",
       " 0.48000000000000004,\n",
       " 0.48000000000000004,\n",
       " 0.48000000000000004,\n",
       " 0.48000000000000004,\n",
       " 0.03,\n",
       " 0.01,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.02,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.11,\n",
       " 0.11,\n",
       " 0.11,\n",
       " 0.11,\n",
       " 0.1,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.02,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.01,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.05,\n",
       " 0.02,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.03,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.04,\n",
       " 0.060000000000000005,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.04000000000000001,\n",
       " 0.04000000000000001,\n",
       " 0.030000000000000006,\n",
       " 0.010000000000000007,\n",
       " 0.010000000000000007,\n",
       " 0.010000000000000007,\n",
       " 0.010000000000000007,\n",
       " 0.010000000000000007,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.010000000000000007,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.08,\n",
       " 0.08,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.11000000000000001,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.060000000000000005,\n",
       " 0.1,\n",
       " 0.11000000000000001,\n",
       " 0.12000000000000001,\n",
       " 0.13,\n",
       " 0.11000000000000001,\n",
       " 0.09000000000000001,\n",
       " 0.09000000000000001,\n",
       " 0.09000000000000001,\n",
       " 0.05,\n",
       " 0.020000000000000007,\n",
       " 0.010000000000000007,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.020000000000000007,\n",
       " 0.04000000000000001,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.07,\n",
       " 0.05,\n",
       " 0.030000000000000006,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.030000000000000006,\n",
       " 0.030000000000000006,\n",
       " 0.030000000000000006,\n",
       " 0.030000000000000006,\n",
       " 0.030000000000000006,\n",
       " 0.030000000000000006,\n",
       " 0.030000000000000006,\n",
       " 0.030000000000000006,\n",
       " 0.010000000000000007,\n",
       " 0.010000000000000007,\n",
       " 0.010000000000000007,\n",
       " 0.010000000000000007,\n",
       " 0.010000000000000007,\n",
       " 0.010000000000000007,\n",
       " 0.010000000000000007,\n",
       " 0.010000000000000007,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precip_8_Hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8291c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'Precip_8_Hr' list as a new column in the dataframe\n",
    "df_GOES_meteo_combined['Precip_8_Hr'] = Precip_8_Hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "beb12cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_true = df_GOES_meteo_combined['is_snow_precip'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "90e62682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063e449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5310e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bd257a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOES_meteo_combined = df_GOES_meteo_combined_all.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fad77f",
   "metadata": {},
   "source": [
    "### 1D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "825ae96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 17:29:00.570155: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, Dropout\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d378b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "# # Extract the data from dataframe\n",
    "# X = np.array(df_GOES_meteo_combined['Lake_data_1D'].tolist())\n",
    "# y = np.array(df_GOES_meteo_combined['Precip_8_Hr'].tolist())\n",
    "\n",
    "# # Fill NaN values with 0\n",
    "# X = np.nan_to_num(X)\n",
    "# y = np.nan_to_num(y)\n",
    "\n",
    "# # Split the data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# # Reshape the data to fit the conv1d model\n",
    "# X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "# X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# # Define the model\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "# model.add(Conv1D(64, 3, activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# # Evaluate the model\n",
    "# score = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print(\"Test loss:\", score)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Calculate accuracy of the model\n",
    "# accuracy = np.mean(np.abs(y_pred - y_test) <= 0.5)\n",
    "# print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8dc8604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_GOES_meteo_combined['Precip_8_Hr'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "90bdee8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 92.5 GiB for an array with shape (47928, 72, 3599) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     input_data\u001b[38;5;241m.\u001b[39mappend(X[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m72\u001b[39m])\n\u001b[1;32m     27\u001b[0m     output_data\u001b[38;5;241m.\u001b[39mappend(y[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m120\u001b[39m])\n\u001b[0;32m---> 29\u001b[0m input_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m output_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(output_data)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Scale the input data\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/shape_base.py:433\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    431\u001b[0m sl \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m),) \u001b[38;5;241m*\u001b[39m axis \u001b[38;5;241m+\u001b[39m (_nx\u001b[38;5;241m.\u001b[39mnewaxis,)\n\u001b[1;32m    432\u001b[0m expanded_arrays \u001b[38;5;241m=\u001b[39m [arr[sl] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 92.5 GiB for an array with shape (47928, 72, 3599) and data type float64"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, Dropout\n",
    "\n",
    "X = np.stack(df_GOES_meteo_combined['Lake_data_1D'].to_numpy())\n",
    "\n",
    "df_GOES_meteo_combined['is_snow_precip'] = df_GOES_meteo_combined['is_snow_precip'].apply(lambda x: int(round(x)) if isinstance(x, float) and not np.isnan(x) else (int(x) if not np.isnan(x) else 0))\n",
    "\n",
    "y = df_GOES_meteo_combined['is_snow_precip'].values.astype(int)\n",
    "# print(y)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "X = np.nan_to_num(X)\n",
    "y = np.nan_to_num(y)\n",
    "\n",
    "\n",
    "input_data = []\n",
    "output_data = []\n",
    "\n",
    "for i in range(len(X) - 120):\n",
    "    input_data.append(X[i:i+72])\n",
    "    output_data.append(y[i+120])\n",
    "\n",
    "input_data = np.stack(input_data)\n",
    "output_data = np.stack(output_data)\n",
    "\n",
    "\n",
    "# Scale the input data\n",
    "scaler = StandardScaler()\n",
    "input_data_scaled = scaler.fit_transform(input_data.reshape(input_data.shape[0], -1)).reshape(input_data.shape)\n",
    "\n",
    "# Reshape the input data to match Conv1D input shape (batch_size, steps, input_dim)\n",
    "input_data_scaled = input_data_scaled.reshape(input_data_scaled.shape[0], input_data_scaled.shape[1], input_data_scaled.shape[2])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data_scaled, output_data, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mae', 'accuracy'])\n",
    "\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mse', metrics=['mae', 'accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1bb834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc4c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test MSE: {test_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0208d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_test, label='Actual')\n",
    "plt.plot(y_pred, label='Predicted')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Precip_8_Hr')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83243e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf2333",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48fe99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "577414bc",
   "metadata": {},
   "source": [
    "### Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aece4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d490d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack(df_GOES_meteo_combined['Lake_data_2D'].to_numpy())\n",
    "y = df_GOES_meteo_combined['Precip_8_Hr'].values\n",
    "\n",
    "# Fill NaN values with 0\n",
    "X = np.nan_to_num(X)\n",
    "y = np.nan_to_num(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the input data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.reshape(X.shape[0], -1)).reshape(X.shape)\n",
    "\n",
    "# Reshape the input data to match Conv2D input shape (batch_size, height, width, channels)\n",
    "X_scaled = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], X_scaled.shape[2], 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d97f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db505afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56052300",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Test MSE: {test_mse}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2411d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_test, label='Actual')\n",
    "plt.plot(y_pred, label='Predicted')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Precip_8_Hr')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dff564",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [44678, 44702, 44726, 44750, 44775, 44799, 44823, 44847, 44871, 44895, 44919, 44943, 44967, 44991, 45015, 45039, 45063, 45087, 45111, 45135, 45159, 45183, 45207, 45231, 45255, 45279, 45303, 45327, 45351, 45375, 45399, 45423, 45447, 45471, 45495, 45519, 45543, 45567, 45591, 45615, 45639, 45663, 45687, 45711, 45735, 45759, 45783, 45807, 45831, 45855, 45879, 45903, 45927, 45951, 45975, 46000, 46023, 46047, 46071, 46095, 46119, 46143, 46167, 46191, 46215, 46239, 46263, 46287, 46335, 46359, 46383, 46407, 46431, 46455, 46479, 46503, 46527, 46551, 46575, 46599, 46623, 46647, 46671, 46695, 46719, 46743, 46767, 46791, 46815, 46839, 46863, 46887, 46911, 46935, 46959, 46983, 47007, 47031, 47055, 47079, 47103, 47127, 47151, 47174, 47198, 47222, 47246, 47270, 47294, 47318, 47342, 47366, 47390, 47414, 47438, 47462, 47486, 47510, 47534, 47558, 47582, 47606, 47630, 47654, 47678, 47702, 47726, 47750, 47774, 47798, 47822, 47846, 47870, 47893, 47917, 47941, 47965, 47989, 48013, 48037, 48061, 48085, 48109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b5ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ba0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46ac7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44145457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31ce9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather station data exists for  MI-14850-TRAVERSE_CITY_CHERRY_CPTL_AP\n",
      "File exists, reading table!\n",
      "1-D Lake Michigan data exists for  2006Fall  to  2007Spring\n",
      "2-D Lake Michigan data exists for  2006Fall  to  2007Spring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213088/536659257.py:175: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  temp_table = pd.read_csv('NSW_Weather/'+weather_station+'/'+filename, skiprows = 8, skipfooter = 15)\n",
      "100%|██████████| 4368/4368 [00:31<00:00, 138.94it/s]\n",
      "100%|██████████| 4368/4368 [00:14<00:00, 291.74it/s]\n",
      "/tmp/ipykernel_213088/536659257.py:175: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  temp_table = pd.read_csv('NSW_Weather/'+weather_station+'/'+filename, skiprows = 8, skipfooter = 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather station data exists for  MI-14850-TRAVERSE_CITY_CHERRY_CPTL_AP\n",
      "File exists, reading table!\n",
      "1-D Lake Michigan data exists for  2007Fall  to  2008Spring\n",
      "2-D Lake Michigan data exists for  2007Fall  to  2008Spring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4392/4392 [00:32<00:00, 136.33it/s]\n",
      "100%|██████████| 4392/4392 [00:15<00:00, 289.19it/s]\n",
      "/tmp/ipykernel_213088/536659257.py:175: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  temp_table = pd.read_csv('NSW_Weather/'+weather_station+'/'+filename, skiprows = 8, skipfooter = 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather station data exists for  MI-14850-TRAVERSE_CITY_CHERRY_CPTL_AP\n",
      "File exists, reading table!\n",
      "1-D Lake Michigan data exists for  2008Fall  to  2009Spring\n",
      "2-D Lake Michigan data exists for  2008Fall  to  2009Spring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4368/4368 [00:31<00:00, 137.27it/s]\n",
      "100%|██████████| 4368/4368 [00:14<00:00, 292.65it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date as dtdt\n",
    "from pytz import timezone\n",
    "import itertools\n",
    "import math\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "###############################################################################\n",
    "# Important, make sure to use the correct file\n",
    "weather_station = 'MI-14850-TRAVERSE_CITY_CHERRY_CPTL_AP'\n",
    "\n",
    "###############################################################################\n",
    "# In this part, we select the number of years used for the experiment\n",
    "# start_year_lib = [2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "\n",
    "start_year_lib = [2006, 2007, 2008]\n",
    "\n",
    "hour_lib = ['00:00', '01:00', '02:00', '03:00', '04:00', '05:00', '06:00', '07:00', '08:00', '09:00', \n",
    "            '10:00', '11:00', '12:00', '13:00', '14:00', '15:00', '16:00', '17:00',\n",
    "            '18:00', '19:00', '20:00', '21:00', '22:00', '23:00']\n",
    "\n",
    "# Initialize an empty dataframe to store the combined data\n",
    "df_combined_all = pd.DataFrame()\n",
    "\n",
    "# Initialize an empty list to store the lengths of each 'df_GOES_meteo_combined'\n",
    "lengths_list = []\n",
    "\n",
    "\n",
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days) + 1):\n",
    "        yield date1 + timedelta(n)\n",
    "\n",
    "###############################################################################\n",
    "def round_datetime_to_nearest_hour(obj_arr, STATE_ID):\n",
    "    arr_len = len(obj_arr)\n",
    "    Date_CST = []\n",
    "    Time_CST = []\n",
    "    for i in range(arr_len):\n",
    "        # iterate through\n",
    "        date_item = obj_arr['Date'][i]\n",
    "        time_item = obj_arr['Time'][i]\n",
    "        t = datetime.strptime(date_item + \" \" + time_item, \"%Y-%m-%d %H:%M\")\n",
    "        # Calculate the number of minutes past the last full hour\n",
    "        minutes_past_hour = t.minute + t.second / 60\n",
    "        # Round up to the next whole number of hours if the time is more than 30 minutes past the hour,\n",
    "        # or round down to the current hour if it's less than 30 minutes past\n",
    "        if minutes_past_hour >= 30:\n",
    "            num_hours = math.ceil(minutes_past_hour / 60)\n",
    "        else:\n",
    "            num_hours = 0\n",
    "        # Create a new datetime object representing the rounded time\n",
    "        if STATE_ID in ['IL', 'WI']:\n",
    "            # No need to dial back one hour\n",
    "            rounded_time_temp = t + timedelta(hours=num_hours)\n",
    "        else:\n",
    "            rounded_time_temp = t + timedelta(hours=num_hours-1)\n",
    "        rounded_time=datetime(year=rounded_time_temp.year,\n",
    "                         month=rounded_time_temp.month,\n",
    "                         day=rounded_time_temp.day,\n",
    "                         hour=rounded_time_temp.hour, minute=0, second=0)\n",
    "        result_stamp = rounded_time.strftime(\"%Y-%m-%d %H:%M\")\n",
    "        \n",
    "        new_date, new_time = result_stamp.split(' ')\n",
    "        Date_CST.append(new_date)\n",
    "        Time_CST.append(new_time)\n",
    "        \n",
    "    obj_arr['Date_CST'] = Date_CST\n",
    "    obj_arr['Time_CST'] = Time_CST\n",
    "    return obj_arr\n",
    "\n",
    "##############################################################################\n",
    "def check_snow_24_120(df):\n",
    "    does_snow_24_120 = []\n",
    "    for i in range(len(df)):\n",
    "        if i + 120 < len(df):\n",
    "            if any(df['is_snow_precip'].iloc[i+24:i+120]):\n",
    "                does_snow_24_120.append(True)\n",
    "            else:\n",
    "                does_snow_24_120.append(False)\n",
    "        else:\n",
    "            does_snow_24_120.append(False)\n",
    "    df['does_snow_24_120'] = does_snow_24_120\n",
    "    return df\n",
    "    \n",
    "##############################################################################\n",
    "def lake_1D_matcher(df_temp, df_lake_1D_map):\n",
    "    # left join df_temp with df_lake_1D_map based on latitude and longitude\n",
    "    df_merged_temp = pd.merge(df_lake_1D_map, df_temp, on=['latitude', 'longitude'], how='left')\n",
    "\n",
    "    # extract value column into a list\n",
    "    value_temp = df_merged_temp['value'].tolist()\n",
    "\n",
    "    return value_temp\n",
    "    \n",
    "##############################################################################\n",
    "def is_valid_data(df_temp):\n",
    "    \n",
    "    crit_1 = 0\n",
    "    crit_2 = 0\n",
    "    crit_3 = 0\n",
    "        \n",
    "    # Pass in value\n",
    "    i_temp = df_temp.value\n",
    "    \n",
    "\n",
    "    try:\n",
    "        \n",
    "        i_temp_max = i_temp.max().max()\n",
    "\n",
    "        # Acquire mode in the array\n",
    "        i_temp_mode = i_temp.mode()[0]\n",
    "    except:\n",
    "        i_temp_max = 0\n",
    "        i_temp_mode = 0\n",
    "    \n",
    "    # Check Criteria #1:\n",
    "    if i_temp_max <= 0.03:\n",
    "        crit_1 = 1\n",
    "    \n",
    "    # Check Criteria #2:\n",
    "    if i_temp_mode <= 0.02:\n",
    "        crit_2 = 1\n",
    "    \n",
    "    # Check Criteria #3\n",
    "    if len(i_temp) <= 3000:\n",
    "        crit_3 = 1\n",
    "        \n",
    "    crit_sum = crit_1 + crit_2 + crit_3\n",
    "    \n",
    "    if crit_sum > 0:\n",
    "        cond = False\n",
    "    else:\n",
    "        cond = True\n",
    "        \n",
    "    return cond\n",
    "    \n",
    "    \n",
    "def cloud_finder(value_temp):\n",
    "    # Deduct 0.1 from all elements in the array\n",
    "    value_temp = [x - 0.1 for x in value_temp]\n",
    "    \n",
    "    # Count the number of elements that are larger than or equal to 0\n",
    "    count = sum(1 for x in value_temp if x >= 0)\n",
    "    \n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for start_year in start_year_lib:\n",
    "    ## It is always the case\n",
    "    end_year = start_year + 1\n",
    "\n",
    "    filename = weather_station[0:9]+str(start_year)+'Fall-'+str(end_year)+'Spring.csv'\n",
    "\n",
    "    ## Extract the state indicator\n",
    "    STATE_ID = filename[:2]\n",
    "    STATE_2_LTR = filename[:2]\n",
    "    # print(STATE_2_LTR)\n",
    "\n",
    "    ###########################################################################\n",
    "    # Check if they exist\n",
    "    if os.path.exists('NSW_Weather/'+weather_station+'/'):\n",
    "        print('Weather station data exists for ', weather_station)\n",
    "    else:\n",
    "        print('Weather station data does not exist for ', weather_station)\n",
    "        \n",
    "    if os.path.isfile('NSW_Weather/'+weather_station+'/'+filename):\n",
    "        print(\"File exists, reading table!\")\n",
    "        temp_table = pd.read_csv('NSW_Weather/'+weather_station+'/'+filename, skiprows = 8, skipfooter = 15)\n",
    "    else:\n",
    "        print(\"File does not exist, please rewind!\")\n",
    "    \n",
    "    ###########################################################################\n",
    "    # Go get the satellite imagery data\n",
    "\n",
    "    folder_name = 'zone_0_'+filename[9:13]+'Fall_'+filename[18:22]+'Spring'\n",
    "    # print(folder_name)\n",
    "\n",
    "    # Acquire the folder location for 2-D lake data based on folder_name\n",
    "    folder_name_2D = folder_name[0:7]+'T_'+folder_name[7:]\n",
    "    # print(folder_name_2D)\n",
    "\n",
    "    # Add the parent folder name\n",
    "    parent_path = 'GOES_Hourly_Statistics/'\n",
    "\n",
    "    # Check if they exist\n",
    "    if os.path.exists(parent_path + folder_name):\n",
    "        print('1-D Lake Michigan data exists for ', folder_name[7:15], ' to ', folder_name[16:])\n",
    "    else:\n",
    "        print('1-D Lake Michigan data does not exist for ', folder_name[7:15], ' to ', folder_name[16:])\n",
    "        \n",
    "    if os.path.exists(parent_path + folder_name_2D):\n",
    "        print('2-D Lake Michigan data exists for ', folder_name_2D[9:17], ' to ', folder_name_2D[18:])\n",
    "    else:\n",
    "        print('2-D Lake Michigan data does not exist for ', folder_name[9:17], ' to ', folder_name_2D[18:])\n",
    "\n",
    "    ##########################################################################\n",
    "    # Start a new part\n",
    "#     print(type(start_year))\n",
    "#     print(type(start_year))\n",
    "#     print(type(start_year))\n",
    "#     print(type(start_year))\n",
    "    temp_start = int(start_year)\n",
    "    temp_end = int(end_year)\n",
    "    start_dt = dtdt(temp_start, 10, 1)\n",
    "    end_dt = dtdt(temp_end, 3, 31)\n",
    "    weather_date_theo = [dt.strftime(\"%Y%m%d\") for dt in daterange(start_dt, end_dt)]\n",
    "    csv_date_list = list(itertools.chain.from_iterable(itertools.repeat(x, 24) for x in weather_date_theo))\n",
    "    csv_time_list = hour_lib * len(weather_date_theo)\n",
    "    # Example usage\n",
    "    weather_with_CST = round_datetime_to_nearest_hour(temp_table, STATE_ID)\n",
    "    weather_with_CST['Precip (in)'] = weather_with_CST['Precip (in)'].replace('m', 0).astype(float)\n",
    "    weather_with_CST['Temp (F)'] = weather_with_CST['Temp (F)'].replace('M', 200).astype(int)\n",
    "    is_snow_precip = ((weather_with_CST['Precip (in)'] > 0) & (weather_with_CST['Temp (F)']  <= 32)).tolist()\n",
    "    weather_with_CST['is_snow_precip'] = is_snow_precip\n",
    "    weather_with_CST = check_snow_24_120(weather_with_CST)\n",
    "    # Initialize empty list to store results\n",
    "    # does_snow_24_120 = []\n",
    "\n",
    "    # # Iterate through each row in the 'is_snow_precip' column\n",
    "    # for i in range(len(weather_with_CST['is_snow_precip'])):\n",
    "        \n",
    "    #     # Check if the next 24 to 120 rows contain more than 2 True values\n",
    "    #     if i+120 < len(weather_with_CST['is_snow_precip']):\n",
    "    #         rolling_sum = weather_with_CST['is_snow_precip'][i+24:i+121].rolling(window=25).sum()\n",
    "    #         count_true = np.sum(rolling_sum > 2)\n",
    "    #     else:\n",
    "    #         count_true = 0\n",
    "        \n",
    "    #     # Append the result to the list\n",
    "    #     does_snow_24_120.append(count_true)\n",
    "\n",
    "    # # Add the list to the dataframe\n",
    "    # weather_with_CST['does_snow_24_120'] = does_snow_24_120\n",
    "    Date_CST = pd.Series(csv_date_list, name = 'Date_CST')\n",
    "    Time_CST = pd.Series(csv_time_list, name = 'Time_CST')\n",
    "\n",
    "    # Start to retrieve files\n",
    "    # Get a list of all files in the directory\n",
    "    file_list_1D = os.listdir(parent_path + folder_name)\n",
    "\n",
    "    # Sort the list of files (Necessary on Linux)\n",
    "    file_list_1D.sort()\n",
    "\n",
    "    # Get a list of all files in the directory\n",
    "    file_list_2D = os.listdir(parent_path + folder_name_2D)\n",
    "\n",
    "    # Sort the list of files (Necessary on Linux)\n",
    "    file_list_2D.sort()\n",
    "\n",
    "    intend_date_list = []\n",
    "\n",
    "    for date in csv_date_list:\n",
    "        intend_date = date[:4] + '.' + date[4:6] + '.' + date[6:]\n",
    "        intend_date_list.append(intend_date)\n",
    "    \n",
    "    intend_time_list = [t.replace(':', '') for t in csv_time_list]\n",
    "    intend_timestamp_list = [f\"{date}.{time}\" for date, time in zip(intend_date_list, intend_time_list)]\n",
    "    \n",
    "    Date_UTC = []\n",
    "\n",
    "    for date in csv_date_list:\n",
    "        intend_date = date[:4] + '-' + date[4:6] + '-' + date[6:]\n",
    "        Date_UTC.append(intend_date)\n",
    "        \n",
    "    Time_UTC = csv_time_list.copy()\n",
    "    \n",
    "    file_1D_timestamp = []\n",
    "\n",
    "    for filename in file_list_1D:\n",
    "        file_1D = filename[7:22]\n",
    "        file_1D_timestamp.append(file_1D)\n",
    "    \n",
    "    # Define UTC and CST time zones\n",
    "    utc_tz = timezone('UTC')\n",
    "    cst_tz = timezone('Etc/GMT+6')\n",
    "\n",
    "    # Example lists of datetime strings\n",
    "    date_utc_list = Date_UTC.copy()\n",
    "    time_utc_list = Time_UTC.copy()\n",
    "\n",
    "    # Convert datetime strings from UTC to CST\n",
    "    date_cst_list = []\n",
    "    time_cst_list = []\n",
    "    for date_str, time_str in zip(date_utc_list, time_utc_list):\n",
    "        datetime_utc = datetime.strptime(date_str + ' ' + time_str, '%Y-%m-%d %H:%M')\n",
    "        datetime_utc = utc_tz.localize(datetime_utc)\n",
    "        datetime_cst = datetime_utc.astimezone(cst_tz)\n",
    "        date_cst_list.append(datetime_cst.strftime('%Y-%m-%d'))\n",
    "        time_cst_list.append(datetime_cst.strftime('%H:%M'))\n",
    "        \n",
    "    data_dict = {'Date_UTC': Date_UTC,\n",
    "             'Time_UTC': Time_UTC,\n",
    "             'Date_CST': date_cst_list,\n",
    "             'Time_CST': time_cst_list,\n",
    "             'intend_timestamp_list': intend_timestamp_list}\n",
    "\n",
    "    # create the DataFrame using the dictionary\n",
    "    df_GOES_time_lib = pd.DataFrame(data_dict)\n",
    "    \n",
    "    df_GOES_file_lib = pd.DataFrame({'file_timestamp': file_1D_timestamp, 'file_list_1D': file_list_1D, 'file_list_2D': file_list_2D})\n",
    "    \n",
    "    df_GOES_combined = pd.merge(df_GOES_time_lib, df_GOES_file_lib, left_on='intend_timestamp_list', right_on='file_timestamp', how='left')\n",
    "    df_GOES_combined.fillna('None', inplace=True)\n",
    "    \n",
    "    output_dir = 'output/GOES_file_lib_dir/'\n",
    "    output_csv_name = str(start_year)+'Fall_'+str(end_year)+'Spring_GOES_lib.csv'\n",
    "\n",
    "    output_file_path = os.path.join(output_dir, output_csv_name)\n",
    "\n",
    "    df_GOES_combined.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    ###################\n",
    "    df_reference_1D = pd.read_csv('02-05-2023/zone_0_sample_take_2/' + 'goes15.2016.12.12.1700.v01.nc-var1-t0.csv')\n",
    "    table_1D_len = df_reference_1D.shape[0]\n",
    "    df_lake_1D_map = df_reference_1D[['latitude', 'longitude']].copy()\n",
    "    matched_1D_file_list = df_GOES_combined['file_list_1D'].tolist()\n",
    "    matched_2D_file_list = df_GOES_combined['file_list_2D'].tolist()\n",
    "    matrix = df_reference_1D.values\n",
    "    df_tester_again = pd.read_csv('02-05-2023/zone_0_sample_take_2/' + 'goes15.2016.12.08.1200.v01.nc-var1-t0.csv')\n",
    "    temp_result_tester = lake_1D_matcher(df_tester_again, df_lake_1D_map)\n",
    "    \n",
    "    ###################\n",
    "    lake_1D_list = []\n",
    "    # lat_lists = []\n",
    "    # lon_lists = []\n",
    "    cond_list = []\n",
    "    count_list = []\n",
    "    cloud_exist_list = []\n",
    "    for file_name in tqdm(matched_1D_file_list):\n",
    "    # for file_name in matched_1D_file_list[1769:1775]:\n",
    "        \n",
    "        try:\n",
    "            temp_file_path = parent_path + folder_name + '/' + file_name\n",
    "    #         print( temp_file_path)\n",
    "    #         print(counter)\n",
    "            df_temp = pd.read_csv(temp_file_path)\n",
    "            value_temp = lake_1D_matcher(df_temp, df_lake_1D_map)\n",
    "            cond = is_valid_data(df_temp)\n",
    "            cond_list.append(cond)\n",
    "            lake_1D_list.append(value_temp)\n",
    "            num_clouds = cloud_finder(value_temp)\n",
    "            count_list.append(num_clouds) \n",
    "            if num_clouds < 720:\n",
    "                exist_temp = False\n",
    "            else:\n",
    "                exist_temp = True\n",
    "            # Replace all NaN values in the 'exist_temp' array with 0.0\n",
    "            exist_temp = np.nan_to_num(exist_temp, nan=0.0)\n",
    "            cloud_exist_list.append(exist_temp)\n",
    "    #         lat_lists.append(lat_list)\n",
    "    #         lon_lists.append(lon_list)\n",
    "        except FileNotFoundError:\n",
    "            lake_1D_list.append(np.zeros(3599))\n",
    "            cond_list.append(False)\n",
    "            count_list.append(0) \n",
    "            cloud_exist_list.append(False)\n",
    "    \n",
    "    # list of matrices\n",
    "    lake_2D_list = []\n",
    "\n",
    "    # loop over file names\n",
    "    for file_name in tqdm(matched_2D_file_list):\n",
    "        try:\n",
    "            # read csv file into dataframe\n",
    "            temp_file_path = parent_path + folder_name_2D + '/' + file_name\n",
    "            df_temp = pd.read_csv(temp_file_path)\n",
    "            df_temp = df_temp.iloc[1:, 1:]\n",
    "            # Replace NaN values in 'values' with 0 in 'df_temp'\n",
    "            df_temp = df_temp.fillna(0)\n",
    "    #         print(df_temp.shape)\n",
    "            # convert dataframe to numpy array/matrix\n",
    "            mat_temp = df_temp.values\n",
    "    #         mat_temp = np.array(df_temp.values.flatten())\n",
    "\n",
    "            # assume df_temp is a DataFrame with multiple columns\n",
    "    #         arrays = [df_temp.iloc[:, i].to_numpy() for i in range(len(df_temp.columns))]\n",
    "    #         mat_temp = arrays\n",
    "        except FileNotFoundError:\n",
    "            # if file does not exist, save NaN\n",
    "            mat_temp = np.zeros((105, 79))\n",
    "        \n",
    "        # append matrix to list\n",
    "        lake_2D_list.append(mat_temp)\n",
    "        \n",
    "    df_GOES_combined['lake_1D_list'] = lake_1D_list\n",
    "    df_GOES_combined['lake_2D_list'] = lake_2D_list\n",
    "    df_GOES_combined['data_usable'] = cond_list\n",
    "    df_GOES_combined['cloud_count'] = count_list\n",
    "    df_GOES_combined['cloud_exist'] = cloud_exist_list\n",
    "    \n",
    "    df_GOES_meteo_combined = pd.merge(df_GOES_combined, weather_with_CST, on=['Date_CST', 'Time_CST'], how='left')\n",
    "    \n",
    "    column_names = df_GOES_meteo_combined.columns.tolist()\n",
    "    \n",
    "    df_GOES_meteo_combined = df_GOES_meteo_combined.drop(['Date', 'Time', 'intend_timestamp_list', 'file_timestamp'], axis=1)\n",
    "    \n",
    "    df_GOES_meteo_combined.rename(columns={'file_list_1D': 'File_name_for_1D_lake'}, inplace=True)\n",
    "    df_GOES_meteo_combined.rename(columns={'file_list_2D': 'File_name_for_2D_lake'}, inplace=True)\n",
    "    df_GOES_meteo_combined.rename(columns={'lake_1D_list': 'Lake_data_1D'}, inplace=True)\n",
    "    df_GOES_meteo_combined.rename(columns={'lake_2D_list': 'Lake_data_2D'}, inplace=True)\n",
    "    \n",
    "    column_names = df_GOES_meteo_combined.columns.tolist()\n",
    "    # Concatenate the temporary data to the 'df_combined_all' dataframe\n",
    "    df_combined_all = pd.concat([df_combined_all, df_GOES_meteo_combined], ignore_index=True)\n",
    "    \n",
    "    # Store the length of 'df_GOES_meteo_combined' in the 'lengths_list'\n",
    "    lengths_list.append(len(df_GOES_meteo_combined))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "414bcf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13129, 30)\n",
      "[4368, 4393, 4368]\n"
     ]
    }
   ],
   "source": [
    "# df_GOES_meteo_combined.head(5)\n",
    "print(df_combined_all.shape)\n",
    "print(lengths_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9859c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
